{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanved RAG (Part 2)\n",
    "\n",
    "Continuation from [first part](https://github.com/jzamalloa1/langchain_learning/blob/main/advanced_rag.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, os, pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import random\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import JsonOutputToolsParser, JsonOutputKeyToolsParser\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent, create_react_agent, Tool\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain import hub\n",
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Logical and Semantic Routing </center>\n",
    "\n",
    "<p>\n",
    "<img src=\"ILLUSTRATIONS/rag_diagram_routing.png\" \n",
    "      width=\"65%\" height=\"auto\"\n",
    "      style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "Illustration [reference](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Routing\n",
    "Used in routing to appropriate source choice (ie. Vector DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class RouterQuery(BaseModel):\n",
    "    \"\"\"Route user query to most relevant data source\"\"\"\n",
    "\n",
    "    datasource: Literal[\"python_docs\", \"web_browser\"] = Field(\n",
    "        ...,\n",
    "        description = \"Given a user question choose the most appropriate datasource to answer it\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(RouterQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert router of user's questions. Based on the question asked, route it to\n",
    "the appropriate data source\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define router\n",
    "router = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouterQuery(datasource='python_docs')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "how should I calcuate the mean of two vectors in numpy?\n",
    "\"\"\"\n",
    "\n",
    "router_result = router.invoke({\"question\":query})\n",
    "router_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouterQuery(datasource='web_browser')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "what is the weather in NYC today?\n",
    "\"\"\"\n",
    "\n",
    "router_result = router.invoke({\"question\":query})\n",
    "router_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'web_broswer'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_result.datasource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a *mechanic chain* to route query (incorporate into our main chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.utils.math import cosine_similarity\n",
    "\n",
    "def choose_route(router_output):\n",
    "    if \"python_docs\" in router_output.datasource.lower():\n",
    "        return \"chain for python docs...\"\n",
    "    elif \"web_browser\" in router_output.datasource.lower():\n",
    "        return \"chain for web browser...\"\n",
    "    else:\n",
    "        return \"throw error...\"\n",
    "    \n",
    "full_chain = router | RunnableLambda(choose_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chain for web browser...'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chain for web browser...'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\":\"what is the One Piece\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Routing\n",
    "Used in routing to appropriate prompt.\n",
    "\n",
    "This is done by choosing the prompt that has the closest similarity to the user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define various prompts\n",
    "one_piece_prompt = \"\"\"\n",
    "You are an expert in all things One Piece, the famous manga about Monkey D. Luffy.\n",
    "You know the story behind all the characters, their history and the convoluted stories\n",
    "within One Piece. When you don't know and answer, just say that you don't know.\n",
    "\n",
    "Question: {query}\n",
    "\"\"\"\n",
    "\n",
    "peruvian_soccer_prompt = \"\"\"\n",
    "You are an expert Peruvian soccer scout that is familiar with the Peruvian Liga 1, its teams,\n",
    "their stats and know all the relevant players today. You know which major tournaments the \n",
    "teams are participating in and their stats. You reply with stats to all the user's questions\n",
    "when possible.\n",
    "\n",
    "Question: {query}\n",
    "\"\"\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_templates = [one_piece_prompt, peruvian_soccer_prompt]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to route prompt\n",
    "def prompt_router(input):\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"]) # Confirm on chain's input RunnablePassthrough() key\n",
    "\n",
    "    query_similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "\n",
    "    top_prompt = prompt_templates[query_similarity.argmax()] #Choose top prompt\n",
    "\n",
    "    print(\"Using One Piece prompt\" if top_prompt == one_piece_prompt else \"Using Peruvian Soccer prompt\")\n",
    "\n",
    "    return ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            HumanMessagePromptTemplate.from_template(top_prompt)\n",
    "        ]    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It not only chooses the prompt, but as a `RunnableLambda` it embeds the query in the prompt itself to be passed to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using One Piece prompt\n",
      "messages=[HumanMessage(content=\"\\nYou are an expert in all things One Piece, the famous manga about Monkey D. Luffy.\\nYou know the story behind all the characters, their history and the convoluted stories\\nwithin One Piece. When you don't know and answer, just say that you don't know.\\n\\nQuestion: Who is Luffy?\\n\")]\n"
     ]
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"query\":RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"Who is Luffy?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing complete prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cos\n",
      "after cos\n",
      "Using One Piece prompt\n",
      "Monkey D. Luffy is the main protagonist of the manga and anime series \"One Piece,\" created by Eiichiro Oda. He is a young pirate with the dream of becoming the Pirate King by finding the legendary treasure known as \"One Piece,\" left by the previous Pirate King, Gol D. Roger. Luffy is the captain of the Straw Hat Pirates, a diverse crew of pirates he has assembled on his journey across the Grand Line and the New World.\n",
      "\n",
      "Luffy is distinguished by his optimistic, carefree, and adventurous personality. Despite his seemingly simple-mindedness, he has a strong sense of justice and an unwavering determination to protect his friends and those he considers innocent. Luffy possesses the ability to stretch his body like rubber after inadvertently eating a Devil Fruit known as the Gomu Gomu no Mi (Gum-Gum Fruit) when he was a child. This ability, while granting him immense strength and flexibility, also renders him unable to swim, a significant handicap for a pirate.\n",
      "\n",
      "Throughout the series, Luffy gathers a close-knit crew, each with their own unique backgrounds, dreams, and abilities. His notable feats include challenging and defeating various powerful enemies, such as members of the Shichibukai (Seven Warlords of the Sea), the Yonko (Four Emperors), and officers of the Marines. His actions and charisma have earned him a rapidly growing reputation and a substantial bounty on his head, reflecting his threat to the World Government and his progression towards his goal of becoming the Pirate King.\n",
      "\n",
      "Luffy's heritage is also significant; he is the son of Monkey D. Dragon, the leader of the Revolutionary Army, which seeks to overthrow the World Government, and the grandson of Monkey D. Garp, a vice admiral of the Marines. Despite his family's complex positions within the world's power structures, Luffy remains focused on his quest for adventure and the pursuit of his dream.\n"
     ]
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"query\":RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"Who is Luffy?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Peruvian Soccer prompt\n",
      "Los Chankas es un equipo de fútbol peruano que actualmente participa en la Liga 2, la segunda división del sistema de ligas de fútbol en Perú. No forman parte de la Liga 1, que es la máxima categoría del fútbol peruano. El equipo representa a la región de Apurímac y su nombre hace referencia al antiguo pueblo de los Chankas, que habitaba en esa zona del país. Hasta la fecha de corte de mi conocimiento en 2023, Los Chankas están trabajando para ascender a la Liga 1, compitiendo en la Liga 2 y buscando mejorar su rendimiento y posición en el torneo para lograr su objetivo de ascenso.\n"
     ]
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"query\":RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"Quienes son Los Chankas en Peru?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
