{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Agent Framework with Langchain Release v0.1.0\n",
    "\n",
    "<p>\n",
    "<img src=\"https://blog.langchain.dev/content/images/size/w1248/format/webp/2024/01/V0.1.0_Export--1-.png\" \n",
    "      width=\"35%\" height=\"auto\"\n",
    "      style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "[Update notes](https://blog.langchain.dev/langchain-v0-1-0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.document_loaders import WebBaseLoader, Docx2txtLoader, UnstructuredWordDocumentLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools are the mini-engine which make the Agent work\n",
    "\n",
    "Load the Langchain built-in tool Tavily for live online search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.alaskacommons.com/sporting-cristal-vs-sport-boys-live-rimenses-win-3-0-in-liga-1-apertura-2024/123235/',\n",
       "  'content': 'Sporting Cristal vs Sport Boys LIVE: ‘Rimenses’ win 3-0 in Liga 1 Apertura 2024 February 4, 2024 // News Team  duel being between Sporting Cristal and Sport Boys. Both teams have a rich history and aim to be protagonists in League  in defense for Cristal.  Sporting Cristal is leading 3-0 against Sport Boys at the end of the first half. Cazonatti scored a goal for SportingFebruary 4, 2024 // News Team Sporting Cristal is leading 3-0 against Sport Boys at the end of the first half. Cazonatti scored a goal for Sporting Cristal, establishing their lead in Callao. Quispe almost made a mistake by failing to catch a cross from Ignácio. Sport Boys are struggling to put together passes and create offensive plays.'},\n",
       " {'url': 'https://www.vsstats.com/football/2024-02-04/sport-boys-vs-sporting-cristal',\n",
       "  'content': 'Sport Boys VS Sporting Cristal Team Stats Primera Division H2H Last matches Line Up Injuries Standings Primera Division  Sporting Cristal Trend :  Sport Boys Trend :  Share This Match ABOUT VSstats offers you Football Statistics and Livescore covering more than 1000+ leagues.Primera Division Sport Boys vs Sporting Cristal match preview on 04.02.2024: team stats, match H2H, last results, lineups, injuries, standings, pre-match odds, over/under trend, BTTS trend'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_search.invoke(\"Cuanto quedo el Boys contra el Cristal?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Retrieval part of the tool\n",
    "\n",
    "Recall that retrievers need:\n",
    "1. Source text\n",
    "2. Document loader\n",
    "3. Text splitter\n",
    "4. Embedding model\n",
    "5. Vector store\n",
    "6. Actual retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll try two different word docx loaders and one pdf loader (word doc converted to pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredWordDocumentLoader(\"sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx\", mode=\"elements\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Source Data Mapping Approach to CDMV5.0.1', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'category_depth': 0, 'last_modified': '2024-02-04T20:19:13', 'page_number': 1, 'languages': ['eng'], 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title'}),\n",
       " Document(page_content='', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'languages': ['eng'], 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'PageBreak'}),\n",
       " Document(page_content='Table name: stem_table', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'category_depth': 0, 'last_modified': '2024-02-04T20:19:13', 'page_number': 2, 'languages': ['eng'], 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title'}),\n",
       " Document(page_content='Reading from sample_medical_claims_20170502.csv', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'category_depth': 0, 'last_modified': '2024-02-04T20:19:13', 'page_number': 2, 'languages': ['eng'], 'parent_id': 'd5616637803e75a3291f57e33775368d', 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText'}),\n",
       " Document(page_content='We pull all data into the STEM and we then allow the Vocabulary to decide which CDM table the data lands in.', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'category_depth': 0, 'last_modified': '2024-02-04T20:19:13', 'page_number': 2, 'languages': ['eng'], 'parent_id': 'd5616637803e75a3291f57e33775368d', 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText'})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(docs))\n",
    "docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47031"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(docs[i].dict()[\"page_content\"]) for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(\"sample_docs/WebMD_PBM_ETL_5.0.1_20170606.pdf\")\n",
    "pdf_pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Source Data Mapping Approach to CDMV5.0.1', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'category_depth': 0, 'last_modified': '2024-02-04T20:19:13', 'page_number': 1, 'languages': ['eng'], 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title'}),\n",
       " Document(page_content='Table name: stem_table', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'category_depth': 0, 'last_modified': '2024-02-04T20:19:13', 'page_number': 2, 'languages': ['eng'], 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title'}),\n",
       " Document(page_content='Reading from sample_medical_claims_20170502.csv', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'category_depth': 0, 'last_modified': '2024-02-04T20:19:13', 'page_number': 2, 'languages': ['eng'], 'parent_id': 'd5616637803e75a3291f57e33775368d', 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText'}),\n",
       " Document(page_content='We pull all data into the STEM and we then allow the Vocabulary to decide which CDM table the data lands in.', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'category_depth': 0, 'last_modified': '2024-02-04T20:19:13', 'page_number': 2, 'languages': ['eng'], 'parent_id': 'd5616637803e75a3291f57e33775368d', 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText'}),\n",
       " Document(page_content='EXTRA COLUMNS FOR STEM', metadata={'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx', 'category_depth': 0, 'last_modified': '2024-02-04T20:19:13', 'page_number': 2, 'languages': ['eng'], 'file_directory': 'sample_docs', 'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title'})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(pdf_pages))\n",
    "pdf_pages[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Using DIAGNOSIS_PRIORITY: 1 = 44786627 - Primary Condition 2+ = 44786629 - Secondary Condition PROCEDURE_CODE: ================ Using PRINCIPAL_PROC_IND 1= 44786630 Primary Procedure NULL/\\'\\' = 44786631-Secondary Procedure =====PHARMACY_CLAIMS===== ========================== NDC_CODE ========= When DATA_VENDOR = \"WebMD\" then 38000175 /*Prescription dispensed in pharmacy*/ When DATA_VENDOR = \"Private Source 17\" then 38000177 /*Prescription written*/ ELSE 0 For \"Private Source 17\" we are requesting a new data type of \"Drug from Claim\" start_date DATE end_date DATE start_time TIME NULL days_supply INTEGER =====MEDICAL_CLAIMS===== ======================== NULL =====PHARMACY_CLAIMS===== ========================== NDC_CODE ========= DAYS_SUPPLY dose_unit_concept_id INTEGER 0 dose_unit_source_value CHARACTER VARYING NULL effective_drug_dose FLOAT NULL lot_number CHARACTER VARYING NULL modifier_concept_id INTEGER =====MEDICAL_CLAIMS===== ======================== DIAGNOSIS_CODE: ================ 0 PROCEDURE_CODE: ================ Using PROCEDURE_MODIFIER_1 Use the code in Section 3.1.1. When mapping PROCEDURE_CODE determine what the VOCABULARY_ID is, then you\\'ll need to use the \"Modifier\" vocabulary for that same VOCABULARY.  Example, if you the PROCEDURE_CODE\\'s VOCABULARY_ID is CPT4 then the MODIFIER_CONCEPT_ID should use the following map: WHERE SOURCE_CONCEPT_CLASS_ID IN (\\'CPT4 Modifier\\') AND TARGET_CONCEPT_CLASS_ID IN (\\'CPT4 Modifier\\') The list of modifiers are: --CPT4 Modifier --HCPC modifier It is limitation that we are not pulling over PROCEDURE_MODIFIER_2-4 however they are only used about 3% of the time. =====PHARMACY_CLAIMS===== ========================== 0 operator_concept_id INTEGER 0 qualifier_concept_id INTEGER 0 qualifier_source_value CHARACTER VARYING NULL quantity INTEGER =====MEDICAL_CLAIMS===== ======================== DIAGNOSIS_CODE: ================ NULL PROCEDURE_CODE: ================ Use PROCEDURE_UNITS as is =====PHARMACY_CLAIMS===== ========================== NDC_CODE: ========= DISPENSED_QUANTITY range_high FLOAT NULL range_low FLOAT NULL refills INTEGER =====MEDICAL_CLAIMS===== ======================== NULL =====PHARMACY_CLAIMS===== ========================== NDC_CODE: ========= REFILL_AUTH_AMOUNT route_concept_id INTEGER 0 route_source_value CHARACTER VARYING NULL sig CHARACTER VARYING NULL stop_reason CHARACTER VARYING NULL unique_device_id CHARACTER VARYING NULL unit_concept_id INTEGER 0 unit_source_value CHARACTER VARYING NULL value_as_concept_id INTEGER 0 value_as_number DECIMAL NULL value_as_string CHARACTER VARYING NULL value_source_value CHARACTER VARYING NULL anatomic_site_concept_id INTEGER 0 disease_status_concept_id INTEGER 0 specimen_source_id INTEGER NULL anatomic_site_source_value CHARACTER VARYING NULL disease_status_source_value CHARACTER VARYING NULL'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_pages[-1].dict()[\"page_content\"][-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(docs[i].dict()[\"page_content\"]) for i in range(len(pdf_pages))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdfloader() is capturing less characters than docx (unstructured loader()), but, it might be because we are not introducing \"\\n\" or empty characters, which is a good thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's move on to character splitting now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_split = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "pdf_split = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(pdf_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "214\n"
     ]
    }
   ],
   "source": [
    "print(len(docs_split))\n",
    "print(len(pdf_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_content': 'DECIMAL NULL value_as_string CHARACTER VARYING NULL value_source_value CHARACTER VARYING NULL anatomic_site_concept_id INTEGER 0 disease_status_concept_id INTEGER 0 specimen_source_id INTEGER NULL anatomic_site_source_value CHARACTER VARYING NULL disease_status_source_value CHARACTER VARYING NULL',\n",
       " 'metadata': {'source': 'sample_docs/WebMD_PBM_ETL_5.0.1_20170606.docx',\n",
       "  'last_modified': '2024-02-04T20:19:13',\n",
       "  'page_number': 34,\n",
       "  'text_as_html': '<table>\\n<thead>\\n<tr><th>Field                      </th><th>Type             </th><th>Most freq. value  </th><th>Comment                  </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>domain_id                  </td><td>CHARACTER VARYING</td><td>                  </td><td>=====MEDICAL_CLAIMS=====\\n========================\\n\\nDIAGNOSIS_CODE:\\n================\\nDefault domain = CONDITION from unless udpated by a Vocabulary mapping from CONCEPT_ID\\n\\nPROCEDURE_CODE:\\n================\\nDefault domain = PROCEDURE from unless updated by a Vocabulary mapping from CONCEPT_ID\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\nDefault domain = DRUG from unless updated by a Vocabulary mapping from CONCEPT_ID                          </td></tr>\\n<tr><td>person_id                  </td><td>INTEGER          </td><td>                  </td><td>Lookup in PERSON based on</td></tr>\\n<tr><td>visit_occurrence_id        </td><td>INTEGER          </td><td>                  </td><td>TBD                      </td></tr>\\n<tr><td>provider_id                </td><td>INTEGER          </td><td>                  </td><td>=====MEDICAL_CLAIMS=====\\n========================\\n\\nDIAGNOSIS_CODE &amp; PROCEDURE_CODE:\\n================\\nLookup in the PROVIDER table leveraging NPI\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\n\\nNDC_CODE:\\n==========\\nLookup in the PROVIDER table leveraging NPI                          </td></tr>\\n<tr><td>id                         </td><td>INTEGER          </td><td>                  </td><td>Autogenerate             </td></tr>\\n<tr><td>concept_id                 </td><td>INTEGER          </td><td>                  </td><td>If no map, map to 0.\\n\\n=====MEDICAL_CLAIMS=====\\n========================\\n\\nDIAGNOSIS_CODE:\\n================\\n01 = ICD9\\n02 = ICD10\\n\\nUse the code in Section 3.1.2.\\nIf diagnosis_code_qual=01 use the filter\\nWHERE SOURCE_VOCABULARY_ID IN (&#x27;ICD9CM&#x27;)\\nAND TARGET_STANDARD_CONCEPT IS NOT NULL\\nAND TARGET_INVALID_REASON IS NULL\\n\\nIf diagnosis_code_qual=02 use the filter\\nWHERE SOURCE_VOCABULARY_ID IN (&#x27;ICD10CM&#x27;)\\nAND TARGET_STANDARD_CONCEPT IS NOT NULL\\nAND TARGET_INVALID_REASON IS NULL\\n\\nPROCEDURE_CODE:\\n================\\nUse the code in Section 3.1.2.\\nWHERE SOURCE_VOCABULARY_ID IN (&#x27;ICD9Proc&#x27;,&#x27;HCPCS&#x27;,&#x27;CPT4&#x27;, &#x27;ICD10PCS&#x27;)\\nAND TARGET_STANDARD_CONCEPT IS NOT NULL\\nAND TARGET_INVALID_REASON IS NULL\\nAND TARGET_CONCEPT_CLASS_ID NOT IN (&#x27;HCPCS Modifier&#x27;,&#x27;CPT4 Modifier&#x27;,&#x27;CPT4 Hierarchy&#x27;, &#x27;ICD10PCS Hierarchy&#x27;)\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\n\\nNDC_CODE\\n=========\\nUse the code in Section 3.1.2.\\nWHERE SOURCE_VOCABULARY_ID IN (&#x27;NDC&#x27;)\\nAND TARGET_STANDARD_CONCEPT IS NOT NULL\\nAND TARGET_INVALID_REASON IS NULL\\nAND SVCDATE BETWEEN SOURCE_VALID_START_DATE AND SOURCE_VALID_END_DATE\\n\\nWhen mapping prescription drug, try map the 11-digit NDC code to SOURCE_CODE in OMOP vocab first to see if you make a map. If no mapping found, try the first 9 digits of NDC code to SOURCE_CODE to see if you make a map.  To be considered a valid mapping DATE_SERVICE must fall between SOURCE_VALID_START_DATE and SOURCE_VALID_END_DATE                          </td></tr>\\n<tr><td>source_value               </td><td>CHARACTER VARYING</td><td>                  </td><td>=====MEDICAL_CLAIMS=====\\n========================\\n\\nDIAGNOSIS_CODE:\\n================\\nDIAGNOSIS_CODE\\n\\nPROCEDURE_CODE:\\n================\\nPROCEDURE_CODE\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\n\\nNDC_CODE:\\n==========\\nNDC_CODE\\n\\nDo not change source value if a 9 digit NDC is used over 11 digit.                          </td></tr>\\n<tr><td>source_concept_id          </td><td>INTEGER          </td><td>                  </td><td>If no map, map to 0.\\n\\n=====MEDICAL_CLAIMS=====\\n========================\\n\\nDIAGNOSIS_CODE:\\n================\\nUse the code in Section 3.1.1.\\nIf diagnosis_code_qual=01 use the filter: WHERE SOURCE_VOCABULARY_ID IN (&#x27;ICD9CM&#x27;)\\nAND TARGET_VOCABULARY_ID IN (&#x27;ICD9CM&#x27;) \\n\\nIf diagnosis_code_qual=02 use the filter: WHERE SOURCE_VOCABULARY_ID IN (&#x27;ICD10CM&#x27;)\\nAND TARGET_VOCABULARY_ID IN (&#x27;ICD10CM&#x27;)\\n\\nPROCEDURE_CODE:\\n================\\nUse the code in Section 3.1.1.\\nWHERE SOURCE_VOCABULARY_ID IN (&#x27;ICD9Proc&#x27;,&#x27;HCPCS&#x27;,&#x27;CPT4&#x27;, &#x27;ICD10PCS&#x27;)\\nAND TARGET_VOCABULARY_ID IN (&#x27;ICD9Proc&#x27;,&#x27;HCPCS&#x27;,&#x27;CPT4&#x27;, &#x27;ICD10PCS&#x27;)\\nAND TARGET_CONCEPT_CLASS_ID NOT IN (&#x27;HCPCS Modifier&#x27;,&#x27;CPT4 Modifier&#x27;, &#x27;CPT4 Hierarchy&#x27;, &#x27;ICD10PCS Hierarchy&#x27;)\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\n\\nNDC_CODE\\n=========\\nUse the code in Section 3.1.1.\\nWHERE SOURCE_VOCABULARY_ID IN (&#x27;NDC&#x27;)\\nAND TARGET_VOCABULARY_ID IN (&#x27;NDC&#x27;)\\nAND SVCDATE BETWEEN SOURCE_VALID_START_DATE AND SOURCE_VALID_END_DATE\\n\\nTo be considered a valid mapping DATE_SERVICE must fall between SOURCE_VALID_START_DATE and SOURCE_VALID_END_DATE                          </td></tr>\\n<tr><td>type_concept_id            </td><td>INTEGER          </td><td>                  </td><td>=====MEDICAL_CLAIMS=====\\n========================\\n\\nDIAGNOSIS_CODE:\\n================\\nUsing DIAGNOSIS_PRIORITY:\\n1 = 44786627 - Primary Condition\\n2+ = 44786629 - Secondary Condition\\n\\nPROCEDURE_CODE:\\n================\\nUsing PRINCIPAL_PROC_IND\\n1= 44786630 Primary Procedure\\nNULL/&#x27;&#x27; = 44786631-Secondary Procedure\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\n\\nNDC_CODE\\n=========\\nWhen DATA_VENDOR = &quot;WebMD&quot; then 38000175 /*Prescription dispensed in pharmacy*/\\nWhen DATA_VENDOR = &quot;Private Source 17&quot; then 38000177 /*Prescription written*/\\nELSE 0\\n\\nFor &quot;Private Source 17&quot; we are requesting a new data type of &quot;Drug from Claim&quot;                          </td></tr>\\n<tr><td>start_date                 </td><td>DATE             </td><td>                  </td><td>                         </td></tr>\\n<tr><td>end_date                   </td><td>DATE             </td><td>                  </td><td>                         </td></tr>\\n<tr><td>start_time                 </td><td>TIME             </td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>days_supply                </td><td>INTEGER          </td><td>                  </td><td>=====MEDICAL_CLAIMS=====\\n========================\\nNULL\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\n\\nNDC_CODE\\n=========\\nDAYS_SUPPLY                          </td></tr>\\n<tr><td>dose_unit_concept_id       </td><td>INTEGER          </td><td>                  </td><td>0                        </td></tr>\\n<tr><td>dose_unit_source_value     </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>effective_drug_dose        </td><td>FLOAT            </td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>lot_number                 </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>modifier_concept_id        </td><td>INTEGER          </td><td>                  </td><td>=====MEDICAL_CLAIMS=====\\n========================\\n\\nDIAGNOSIS_CODE:\\n================\\n0\\n\\nPROCEDURE_CODE:\\n================\\nUsing PROCEDURE_MODIFIER_1\\n\\nUse the code in Section 3.1.1.\\nWhen mapping PROCEDURE_CODE determine what the VOCABULARY_ID is, then you&#x27;ll need to use the &quot;Modifier&quot; vocabulary for that same VOCABULARY.  Example, if you the PROCEDURE_CODE&#x27;s VOCABULARY_ID is CPT4 then the MODIFIER_CONCEPT_ID should use the following map:\\nWHERE SOURCE_CONCEPT_CLASS_ID IN (&#x27;CPT4 Modifier&#x27;)\\nAND TARGET_CONCEPT_CLASS_ID IN (&#x27;CPT4 Modifier&#x27;)\\n\\nThe list of modifiers are:\\n--CPT4 Modifier\\n--HCPC modifier\\n\\nIt is limitation that we are not pulling over PROCEDURE_MODIFIER_2-4 however they are only used about 3% of the time.\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\n0                          </td></tr>\\n<tr><td>operator_concept_id        </td><td>INTEGER          </td><td>                  </td><td>0                        </td></tr>\\n<tr><td>qualifier_concept_id       </td><td>INTEGER          </td><td>                  </td><td>0                        </td></tr>\\n<tr><td>qualifier_source_value     </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>quantity                   </td><td>INTEGER          </td><td>                  </td><td>=====MEDICAL_CLAIMS=====\\n========================\\n\\nDIAGNOSIS_CODE:\\n================\\nNULL\\n\\nPROCEDURE_CODE:\\n================\\nUse PROCEDURE_UNITS as is\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\n\\nNDC_CODE:\\n=========\\nDISPENSED_QUANTITY                          </td></tr>\\n<tr><td>range_high                 </td><td>FLOAT            </td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>range_low                  </td><td>FLOAT            </td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>refills                    </td><td>INTEGER          </td><td>                  </td><td>=====MEDICAL_CLAIMS=====\\n========================\\nNULL\\n\\n=====PHARMACY_CLAIMS=====\\n==========================\\n\\nNDC_CODE:\\n=========\\nREFILL_AUTH_AMOUNT                          </td></tr>\\n<tr><td>route_concept_id           </td><td>INTEGER          </td><td>                  </td><td>0                        </td></tr>\\n<tr><td>route_source_value         </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>sig                        </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>stop_reason                </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>unique_device_id           </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>unit_concept_id            </td><td>INTEGER          </td><td>                  </td><td>0                        </td></tr>\\n<tr><td>unit_source_value          </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>value_as_concept_id        </td><td>INTEGER          </td><td>                  </td><td>0                        </td></tr>\\n<tr><td>value_as_number            </td><td>DECIMAL          </td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>value_as_string            </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>value_source_value         </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>anatomic_site_concept_id   </td><td>INTEGER          </td><td>                  </td><td>0                        </td></tr>\\n<tr><td>disease_status_concept_id  </td><td>INTEGER          </td><td>                  </td><td>0                        </td></tr>\\n<tr><td>specimen_source_id         </td><td>INTEGER          </td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>anatomic_site_source_value </td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n<tr><td>disease_status_source_value</td><td>CHARACTER VARYING</td><td>                  </td><td>NULL                     </td></tr>\\n</tbody>\\n</table>',\n",
       "  'languages': ['eng'],\n",
       "  'parent_id': 'ae5354ac2bc8a6763e23e55740ca8299',\n",
       "  'file_directory': 'sample_docs',\n",
       "  'filename': 'WebMD_PBM_ETL_5.0.1_20170606.docx',\n",
       "  'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n",
       "  'category': 'Table'},\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_split[-1].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's place them in the vector DB by embedding text into a vector space (embedding)\n",
    "We'll use FAISS DB for this exercise and OpenAI's embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_docs = FAISS.from_documents(docs_split, OpenAIEmbeddings())\n",
    "vector_pdfs = FAISS.from_documents(pdf_split, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='Skip to main content\\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default‚ÄãAt LangChain, all of us have LangSmith‚Äôs tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript environments through process.env1.The benefit here is that all calls to LLMs, chains, agents, tools, and retrievers are logged to LangSmith. Around 90% of the time we don‚Äôt even look at the traces, but the 10% of the time that we do‚Ä¶ it‚Äôs so helpful. We can use LangSmith to debug:An unexpected end resultWhy an agent is loopingWhy a chain was slower than expectedHow many tokens an agent usedDebugging‚ÄãDebugging LLMs, chains, and agents can be tough. LangSmith helps solve the following pain points:What was the exact input to the LLM?‚ÄãLLM calls are often tricky and non-deterministic. The inputs/outputs may seem straightforward, given they are technically string ‚Üí string (or chat messages ‚Üí chat message), but this can be misleading as the input string is usually constructed', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='The inputs/outputs may seem straightforward, given they are technically string ‚Üí string (or chat messages ‚Üí chat message), but this can be misleading as the input string is usually constructed from a combination of user input and auxiliary functions.Most inputs to an LLM call are a combination of some type of fixed template along with input variables. These input variables could come directly from user input or from an auxiliary function (like retrieval). By the time these input variables go into the LLM they will have been converted to a string format, but often times they are not naturally represented as a string (they could be a list, or a Document object). Therefore, it is important to have visibility into what exactly the final string going into the LLM is. This has helped us debug bugs in formatting logic, unexpected transformations to user input, and straight up missing user input.To a much lesser extent, this is also true of the output of an LLM. Oftentimes the output of', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content=\"bugs in formatting logic, unexpected transformations to user input, and straight up missing user input.To a much lesser extent, this is also true of the output of an LLM. Oftentimes the output of an LLM is technically a string but that string may contain some structure (json, yaml) that is intended to be parsed into a structured representation. Understanding what the exact output is can help determine if there may be a need for different parsing.LangSmith provides a straightforward visualization of the exact inputs/outputs to all LLM calls, so you can easily understand them.If I edit the prompt, how does that affect the output?‚ÄãSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content=\"try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?‚ÄãIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being made? In what order? What are the inputs and outputs of each call?LangSmith's built-in tracing feature offers a visualization to clarify these sequences. This tool is invaluable for\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content=\"calls are being made? In what order? What are the inputs and outputs of each call?LangSmith's built-in tracing feature offers a visualization to clarify these sequences. This tool is invaluable for understanding intricate and lengthy chains and agents. For chains, it can shed light on the sequence of calls and how they interact. For agents, where the sequence of calls is non-deterministic, it helps visualize the specific sequence for a given run -- something that is impossible to know ahead of time.Why did my chain take much longer than expected?‚ÄãIf a chain takes longer than expected, you need to identify the cause. By tracking the latency of each step, LangSmith lets you identify and possibly eliminate the slowest components.How many tokens were used?‚ÄãBuilding and prototyping LLM applications can be expensive. LangSmith tracks the total token usage for a chain and the token usage of each step. This makes it easy to identify potentially costly parts of the chain.Collaborative\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content=\"applications can be expensive. LangSmith tracks the total token usage for a chain and the token usage of each step. This makes it easy to identify potentially costly parts of the chain.Collaborative debugging‚ÄãIn the past, sharing a faulty chain with a colleague for debugging was challenging when performed locally. With LangSmith, we've added a ‚ÄúShare‚Äù button that makes the chain and LLM runs accessible to anyone with the shared link.Collecting examples‚ÄãMost of the time we go to debug, it's because something bad or unexpected outcome has happened in our application. These failures are valuable data points! By identifying how our chain can fail and monitoring these failures, we can test future chain versions against these known issues.Why is this so impactful? When building LLM applications, it‚Äôs often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible.\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content=\"it‚Äôs often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you're wandering blind. You don‚Äôt have any examples to benchmark your changes against.LangSmith addresses this problem by including an ‚ÄúAdd to Dataset‚Äù button for each run, making it easy to add the input/output examples a chosen dataset. You can edit the example before adding them to the dataset to include the expected result, which is particularly useful for bad examples.This feature is available at every step of a nested chain, enabling you to add examples for an end-to-end chain, an intermediary chain (such as a LLM Chain), or simply the LLM or Chat Model.End-to-end chain examples are excellent for testing the overall flow, while single, modular LLM Chain or LLM/Chat Model examples can be beneficial for testing the simplest and most\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='LLM or Chat Model.End-to-end chain examples are excellent for testing the overall flow, while single, modular LLM Chain or LLM/Chat Model examples can be beneficial for testing the simplest and most directly modifiable components.Testing & evaluation‚ÄãInitially, we do most of our evaluation manually and ad hoc. We pass in different', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='inputs, and see what happens. At some point though, our application is performing\\nwell and we want to be more rigorous about testing changes. We can use a dataset\\nthat we‚Äôve constructed along the way (see above). Alternatively, we could spend some\\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content=\"dataset uploading.Once we have a dataset, how can we use it to test changes to a prompt or chain? The most basic approach is to run the chain over the data points and visualize the outputs. Despite technological advancements, there still is no substitute for looking at outputs by eye. Currently, running the chain over the data points needs to be done client-side. The LangSmith client makes it easy to pull down a dataset and then run a chain over them, logging the results to a new project associated with the dataset. From there, you can review them. We've made it easy to assign feedback to runs and mark them as correct or incorrect directly in the web app, displaying aggregate statistics for each test project.We also make it easier to evaluate these runs. To that end, we've added a set of evaluators to the open-source LangChain library. These evaluators can be specified when initiating a test run and will evaluate the results once the test run completes. If we‚Äôre being honest, most\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content=\"evaluators to the open-source LangChain library. These evaluators can be specified when initiating a test run and will evaluate the results once the test run completes. If we‚Äôre being honest, most of these evaluators aren't perfect. We would not recommend that you trust them blindly. However, we do think they are useful for guiding your eye to examples you should look at. This becomes especially valuable as the number of data points increases and it becomes infeasible to look at each one manually.Human Evaluation‚ÄãAutomatic evaluation metrics are helpful for getting consistent and scalable information about model behavior;\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.\\nLangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like creativity or humorTo sample and validate a subset of runs that were auto-evaluated, ensuring the automatic metrics are still reliable and capturing the right informationAll the annotations made using the queue are assigned as \"feedback\" to the source runs, so you can easily filter and analyze them later.', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring‚ÄãAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.We‚Äôve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing ‚Äî mirroring', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content=\"log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing ‚Äî mirroring the debug mode approach.We‚Äôve provided several examples in the LangSmith documentation for extracting insights from logged runs. In addition to guiding you on performing this task yourself, we also provide examples of integrating with third parties for this purpose. We're eager to expand this area in the coming months! If you have ideas for either -- an open-source way to evaluate, or are building a company that wants to do analytics over these runs, please reach out.Exporting datasets‚ÄãLangSmith makes it easy to curate datasets. However, these aren‚Äôt just useful inside LangSmith; they can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other runtime environments without access to the environment, check out the FAQs.‚Ü©PreviousLangSmithNextTracingOn by defaultDebuggingWhat was the exact input to the LLM?If I edit the prompt, how does that affect the output?What is the exact sequence of events?Why did my chain take much longer than expected?How many tokens were used?Collaborative debuggingCollecting examplesTesting & evaluationHuman EvaluationMonitoringExporting datasetsCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(\n",
    "    WebBaseLoader(\"https://docs.smith.langchain.com/overview\").load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
