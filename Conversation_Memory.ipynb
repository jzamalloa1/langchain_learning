{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Agent Conversation and Memory\n",
    "\n",
    "Inspiration taken from https://www.youtube.com/watch?v=X550Zbz_ROE\n",
    "\n",
    "This is important to consider because amount of tokens is not limitless meaning that we need to be wise about the way we store context during an conversation with the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts  import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have setup your environmental variables beforehand\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_ORGANIZATION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate model as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/llms/openai.py:200: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/llms/openai.py:785: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_openai = OpenAI(model_name=\"gpt-4-0613\", temperature=0, max_tokens=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at first ConversationBufferMemory for simpler tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instiate memory where log will be stored. This will be track what user & AI exchange, and stack that into prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start conversational chain. This like LLMChain, can also include a prompt (let's test that in the Playground notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationChain(\n",
    "    llm=llm_openai,\n",
    "    memory=ai_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, I'm El Brian\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello El Brian! It's a pleasure to meet you. I'm an AI developed to assist with information and answer any questions you might have. How can I assist you today?\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"Hi, I'm El Brian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how it keeps track of the conversation even as new queries are requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, I'm El Brian\n",
      "AI: Hello El Brian! It's a pleasure to meet you. I'm an AI developed to assist with information and answer any questions you might have. How can I assist you today?\n",
      "Human: how is your afternoon so far?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As an artificial intelligence, I don't experience time or have personal feelings. But thank you for asking! How can I assist you further?\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"how is your afternoon so far?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice below the memory object where AI/User exchange is logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"Hi, I'm El Brian\", additional_kwargs={}, example=False), AIMessage(content=\"Hello El Brian! It's a pleasure to meet you. I'm an AI developed to assist with information and answer any questions you might have. How can I assist you today?\", additional_kwargs={}, example=False), HumanMessage(content='how is your afternoon so far?', additional_kwargs={}, example=False), AIMessage(content=\"As an artificial intelligence, I don't experience time or have personal feelings. But thank you for asking! How can I assist you further?\", additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "print(ai_memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also stored in the actual Conversation Chain object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, I'm El Brian\n",
      "AI: Hello El Brian! It's a pleasure to meet you. I'm an AI developed to assist with information and answer any questions you might have. How can I assist you today?\n",
      "Human: how is your afternoon so far?\n",
      "AI: As an artificial intelligence, I don't experience time or have personal feelings. But thank you for asking! How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "print(conversation_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above type of memory (ConversationBufferMemory) works well where limited exchanges are expected (~5). Let's look at longer memory types below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore ConversationSummaryMemory for some more exchange intensives scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how this initiation of conversation memory does require the llm input (unlike ConversationMemory above)\n",
    "\n",
    "<u>Why the difference?</u> Because it uses an additional LLM to summarise the log, besides the LLM use for the  (Test multi-LLM usage in Playground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_summary_memory = ConversationSummaryMemory(llm=llm_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationChain(\n",
    "    llm=llm_openai,\n",
    "    memory=ai_summary_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, I'm El Brian\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello El Brian! It's nice to meet you. I'm an AI developed to assist with information and answer questions to the best of my ability. How can I assist you today?\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"Hi, I'm El Brian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the key summary difference now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "El Brian introduces himself to the AI. The AI responds by introducing itself as an assistant developed to provide information and answer questions. It then asks El Brian how it can assist him.\n",
      "Human: How are you doing this evening?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As an artificial intelligence, I don't have feelings or personal experiences, but I'm here and ready to assist you. How can I help you this evening?\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"How are you doing this evening?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They AI summarizes the prior conversation, rather than logging the entire conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Brian introduces himself to the AI, which introduces itself as an assistant developed to provide information and answer questions. When El Brian asks how the AI is doing, it explains that as an AI, it doesn't have feelings or personal experiences, but it's ready to assist. It then asks El Brian how it can help him this evening.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice however in the example that at first we are using more tokens. Let's add more to the log to keep seeing how summarization works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "El Brian introduces himself to the AI, which introduces itself as an assistant developed to provide information and answer questions. When El Brian asks how the AI is doing, it explains that as an AI, it doesn't have feelings or personal experiences, but it's ready to assist. It then asks El Brian how it can help him this evening.\n",
      "Human: Can you help me with identifying the best country to visit in the summer?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Absolutely, I\\'d be happy to help with that. However, the \"best\" country to visit in the summer can depend on a variety of factors such as your personal interests, budget, and the type of experience you\\'re looking for. \\n\\nFor example, if you\\'re interested in history and culture, Italy or Greece could be great options. They offer numerous historical sites, delicious cuisine, and warm Mediterranean weather. \\n\\nIf you\\'re a nature lover, you might consider visiting Canada or Norway. Both countries offer stunning natural landscapes, including mountains, forests, and lakes. The summer months are also a great time to visit these countries as the weather is generally pleasant and the days are long.\\n\\nFor beach lovers, countries like Australia, Indonesia (Bali), or the Maldives might be appealing. They offer beautiful beaches and a variety of water activities.\\n\\nIf you\\'re looking for a unique cultural experience, Japan could be an interesting choice. Summer is the season for many traditional festivals there.\\n\\nCould you provide more details about what you\\'re looking for in a summer vacation? That way, I can give you a more tailored recommendation.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"Can you help me with identifying the best country to visit in the summer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Brian introduces himself to the AI, which introduces itself as an assistant developed to provide information and answer questions. When El Brian asks how the AI is doing, it explains that as an AI, it doesn't have feelings or personal experiences, but it's ready to assist. It then asks El Brian how it can help him this evening. El Brian asks the AI to help him identify the best country to visit in the summer. The AI explains that the \"best\" country can depend on various factors like personal interests, budget, and the type of experience one is looking for. It suggests Italy or Greece for history and culture enthusiasts, Canada or Norway for nature lovers, Australia, Indonesia, or the Maldives for beach lovers, and Japan for a unique cultural experience. The AI then asks El Brian for more details to provide a more tailored recommendation.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is a nice option to store memory in summary so that the 'important' context is maximized in memory (tokens). Let's look at an alternate version of the memory where we store memory (tokens) based on a pre-defined token window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore ConversationBufferWindowMemory to test this pre-defined token-windowed approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversation buffer window memory function sets the last number of interactions we want to keep. We are using 2 as an example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass it to the conversation chain memory argument (as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationChain(\n",
    "    llm=llm_openai,\n",
    "    memory=window_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: I'm looking for travel support\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sure, I'd be happy to help you with that. When it comes to travel support, there are several areas I can assist with. \\n\\n1. Destination Research: I can provide information about various destinations, including local customs, must-see attractions, best times to visit, and more.\\n\\n2. Flight and Accommodation: I can help you find the best deals on flights and accommodations based on your preferences and budget.\\n\\n3. Itinerary Planning: I can suggest an itinerary based on your interests and the duration of your stay.\\n\\n4. Travel Tips: I can provide tips on packing, local transportation, safety, and more.\\n\\n5. Local Cuisine: I can suggest local dishes to try and the best places to eat.\\n\\n6. Emergency Information: I can provide information about local hospitals, embassies, and other important contacts.\\n\\nPlease let me know which area you need help with, or if there's something else you're looking for.\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"I'm looking for travel support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I'm looking for travel support\n",
      "AI: Sure, I'd be happy to help you with that. When it comes to travel support, there are several areas I can assist with. \n",
      "\n",
      "1. Destination Research: I can provide information about various destinations, including local customs, must-see attractions, best times to visit, and more.\n",
      "\n",
      "2. Flight and Accommodation: I can help you find the best deals on flights and accommodations based on your preferences and budget.\n",
      "\n",
      "3. Itinerary Planning: I can suggest an itinerary based on your interests and the duration of your stay.\n",
      "\n",
      "4. Travel Tips: I can provide tips on packing, local transportation, safety, and more.\n",
      "\n",
      "5. Local Cuisine: I can suggest local dishes to try and the best places to eat.\n",
      "\n",
      "6. Emergency Information: I can provide information about local hospitals, embassies, and other important contacts.\n",
      "\n",
      "Please let me know which area you need help with, or if there's something else you're looking for.\n",
      "Human: I would like suggestions for the best places to travel in the US with a low budget\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Absolutely, I can suggest a few budget-friendly travel destinations in the US:\\n\\n1. **Washington, D.C.**: The capital city has numerous free museums and historical sites, including the Smithsonian museums, the National Mall, and the Lincoln Memorial. \\n\\n2. **Yellowstone National Park, Wyoming**: This is a great option if you enjoy outdoor activities. The park's entrance fee is relatively low, and camping can be a cost-effective accommodation option.\\n\\n3. **Austin, Texas**: Known for its vibrant music scene, Austin offers affordable food and entertainment options. You can also enjoy outdoor activities at Lady Bird Lake.\\n\\n4. **New Orleans, Louisiana**: The city is rich in culture, music, and food. You can find budget-friendly accommodations and enjoy free street performances in the French Quarter.\\n\\n5. **Portland, Oregon**: Known for its food trucks, microbreweries, and beautiful parks, Portland can be a budget-friendly option, especially if you're a foodie or nature lover.\\n\\n6. **Grand Canyon, Arizona**: Considered one of the Seven Natural Wonders of the World, the Grand Canyon offers affordable entrance fees and camping options.\\n\\nRemember, traveling off-season, planning ahead, and using public transportation can help you save money.\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"I would like suggestions for the best places to travel in the US with a low budget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that as before (non-summary chain) we have our two past outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: I'm looking for travel support\n",
      "AI: Sure, I'd be happy to help you with that. When it comes to travel support, there are several areas I can assist with. \n",
      "\n",
      "1. Destination Research: I can provide information about various destinations, including local customs, must-see attractions, best times to visit, and more.\n",
      "\n",
      "2. Flight and Accommodation: I can help you find the best deals on flights and accommodations based on your preferences and budget.\n",
      "\n",
      "3. Itinerary Planning: I can suggest an itinerary based on your interests and the duration of your stay.\n",
      "\n",
      "4. Travel Tips: I can provide tips on packing, local transportation, safety, and more.\n",
      "\n",
      "5. Local Cuisine: I can suggest local dishes to try and the best places to eat.\n",
      "\n",
      "6. Emergency Information: I can provide information about local hospitals, embassies, and other important contacts.\n",
      "\n",
      "Please let me know which area you need help with, or if there's something else you're looking for.\n",
      "Human: I would like suggestions for the best places to travel in the US with a low budget\n",
      "AI: Absolutely, I can suggest a few budget-friendly travel destinations in the US:\n",
      "\n",
      "1. **Washington, D.C.**: The capital city has numerous free museums and historical sites, including the Smithsonian museums, the National Mall, and the Lincoln Memorial. \n",
      "\n",
      "2. **Yellowstone National Park, Wyoming**: This is a great option if you enjoy outdoor activities. The park's entrance fee is relatively low, and camping can be a cost-effective accommodation option.\n",
      "\n",
      "3. **Austin, Texas**: Known for its vibrant music scene, Austin offers affordable food and entertainment options. You can also enjoy outdoor activities at Lady Bird Lake.\n",
      "\n",
      "4. **New Orleans, Louisiana**: The city is rich in culture, music, and food. You can find budget-friendly accommodations and enjoy free street performances in the French Quarter.\n",
      "\n",
      "5. **Portland, Oregon**: Known for its food trucks, microbreweries, and beautiful parks, Portland can be a budget-friendly option, especially if you're a foodie or nature lover.\n",
      "\n",
      "6. **Grand Canyon, Arizona**: Considered one of the Seven Natural Wonders of the World, the Grand Canyon offers affordable entrance fees and camping options.\n",
      "\n",
      "Remember, traveling off-season, planning ahead, and using public transportation can help you save money.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I'm looking for travel support\n",
      "AI: Sure, I'd be happy to help you with that. When it comes to travel support, there are several areas I can assist with. \n",
      "\n",
      "1. Destination Research: I can provide information about various destinations, including local customs, must-see attractions, best times to visit, and more.\n",
      "\n",
      "2. Flight and Accommodation: I can help you find the best deals on flights and accommodations based on your preferences and budget.\n",
      "\n",
      "3. Itinerary Planning: I can suggest an itinerary based on your interests and the duration of your stay.\n",
      "\n",
      "4. Travel Tips: I can provide tips on packing, local transportation, safety, and more.\n",
      "\n",
      "5. Local Cuisine: I can suggest local dishes to try and the best places to eat.\n",
      "\n",
      "6. Emergency Information: I can provide information about local hospitals, embassies, and other important contacts.\n",
      "\n",
      "Please let me know which area you need help with, or if there's something else you're looking for.\n",
      "Human: I would like suggestions for the best places to travel in the US with a low budget\n",
      "AI: Absolutely, I can suggest a few budget-friendly travel destinations in the US:\n",
      "\n",
      "1. **Washington, D.C.**: The capital city has numerous free museums and historical sites, including the Smithsonian museums, the National Mall, and the Lincoln Memorial. \n",
      "\n",
      "2. **Yellowstone National Park, Wyoming**: This is a great option if you enjoy outdoor activities. The park's entrance fee is relatively low, and camping can be a cost-effective accommodation option.\n",
      "\n",
      "3. **Austin, Texas**: Known for its vibrant music scene, Austin offers affordable food and entertainment options. You can also enjoy outdoor activities at Lady Bird Lake.\n",
      "\n",
      "4. **New Orleans, Louisiana**: The city is rich in culture, music, and food. You can find budget-friendly accommodations and enjoy free street performances in the French Quarter.\n",
      "\n",
      "5. **Portland, Oregon**: Known for its food trucks, microbreweries, and beautiful parks, Portland can be a budget-friendly option, especially if you're a foodie or nature lover.\n",
      "\n",
      "6. **Grand Canyon, Arizona**: Considered one of the Seven Natural Wonders of the World, the Grand Canyon offers affordable entrance fees and camping options.\n",
      "\n",
      "Remember, traveling off-season, planning ahead, and using public transportation can help you save money.\n",
      "Human: Where should I stay in Austin Texas?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Austin, Texas, has a variety of neighborhoods that cater to different interests and budgets. Here are a few suggestions:\\n\\n1. **Downtown Austin**: This is the heart of the city with easy access to restaurants, bars, and attractions like the Texas State Capitol and Lady Bird Lake. It might be a bit pricier, but the convenience could be worth it.\\n\\n2. **East Austin**: This is a trendy, up-and-coming area with a mix of bungalows and modern condos. It's known for its vibrant nightlife, art scene, and food trucks.\\n\\n3. **South Congress (SoCo)**: This area is known for its shopping, dining, and entertainment. It's a bit more laid-back than downtown but still has plenty of attractions.\\n\\n4. **Hyde Park**: If you're looking for a quieter, more residential area, Hyde Park might be a good fit. It's a historic neighborhood with easy access to the University of Texas at Austin.\\n\\n5. **Rainey Street District**: This area is known for its historic homes turned into bars and restaurants. It's a great place to stay if you enjoy nightlife.\\n\\nRemember, the best place to stay depends on your personal preferences and what you plan to do during your visit.\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"Where should I stay in Austin Texas?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice now that it has lost the first interaction. <u>This is what window memory buffer does</u>, it allows the user to manually set how many windows of memory to keep, therefore reducing the amount of tokens required at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: I would like suggestions for the best places to travel in the US with a low budget\n",
      "AI: Absolutely, I can suggest a few budget-friendly travel destinations in the US:\n",
      "\n",
      "1. **Washington, D.C.**: The capital city has numerous free museums and historical sites, including the Smithsonian museums, the National Mall, and the Lincoln Memorial. \n",
      "\n",
      "2. **Yellowstone National Park, Wyoming**: This is a great option if you enjoy outdoor activities. The park's entrance fee is relatively low, and camping can be a cost-effective accommodation option.\n",
      "\n",
      "3. **Austin, Texas**: Known for its vibrant music scene, Austin offers affordable food and entertainment options. You can also enjoy outdoor activities at Lady Bird Lake.\n",
      "\n",
      "4. **New Orleans, Louisiana**: The city is rich in culture, music, and food. You can find budget-friendly accommodations and enjoy free street performances in the French Quarter.\n",
      "\n",
      "5. **Portland, Oregon**: Known for its food trucks, microbreweries, and beautiful parks, Portland can be a budget-friendly option, especially if you're a foodie or nature lover.\n",
      "\n",
      "6. **Grand Canyon, Arizona**: Considered one of the Seven Natural Wonders of the World, the Grand Canyon offers affordable entrance fees and camping options.\n",
      "\n",
      "Remember, traveling off-season, planning ahead, and using public transportation can help you save money.\n",
      "Human: Where should I stay in Austin Texas?\n",
      "AI: Austin, Texas, has a variety of neighborhoods that cater to different interests and budgets. Here are a few suggestions:\n",
      "\n",
      "1. **Downtown Austin**: This is the heart of the city with easy access to restaurants, bars, and attractions like the Texas State Capitol and Lady Bird Lake. It might be a bit pricier, but the convenience could be worth it.\n",
      "\n",
      "2. **East Austin**: This is a trendy, up-and-coming area with a mix of bungalows and modern condos. It's known for its vibrant nightlife, art scene, and food trucks.\n",
      "\n",
      "3. **South Congress (SoCo)**: This area is known for its shopping, dining, and entertainment. It's a bit more laid-back than downtown but still has plenty of attractions.\n",
      "\n",
      "4. **Hyde Park**: If you're looking for a quieter, more residential area, Hyde Park might be a good fit. It's a historic neighborhood with easy access to the University of Texas at Austin.\n",
      "\n",
      "5. **Rainey Street District**: This area is known for its historic homes turned into bars and restaurants. It's a great place to stay if you enjoy nightlife.\n",
      "\n",
      "Remember, the best place to stay depends on your personal preferences and what you plan to do during your visit.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at now an alternative version, which is a combination of memory buffer of sorts, which mixes a max token limit over re-created summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore ConversationSummaryBufferMemory which applies a maximum token threshold over summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the memory class, and as before with ConversationSummaryMemory(), notice that it needs an llm to also summarize context. Rather than a window also notice that we are using max tokens to threshold memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm_openai,\n",
    "                                          max_token_limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationChain(\n",
    "    llm=llm_openai,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, this is El Brain\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello El Brain! It's a pleasure to meet you. I'm an AI developed to assist with a variety of tasks and answer any questions you might have to the best of my ability. How can I assist you today?\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"Hi, this is El Brain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human introduces themselves as El Brain.\n",
      "AI: Hello El Brain! It's a pleasure to meet you. I'm an AI developed to assist with a variety of tasks and answer any questions you might have to the best of my ability. How can I assist you today?\n",
      "Human: I need help with travel arrengement within the US\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Of course, El Brain! I'd be happy to assist you with your travel arrangements. Could you please provide me with more details? For instance, your departure and destination cities, preferred dates of travel, whether you need assistance with flight bookings, hotel reservations, car rentals, or all of these? The more specific you are, the better I can assist you.\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"I need help with travel arrengement within the US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: El Brain introduces themselves to the AI, which responds by offering its assistance with a variety of tasks. El Brain asks for help with travel arrangements within the US, and the AI asks for more specific details such as departure and destination cities, preferred dates, and whether assistance is needed with flight bookings, hotel reservations, or car rentals.\n",
      "Human: I want to travel over the summer within low budget\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That sounds like a great plan! To help you better, I'll need a bit more information. Could you please specify:\\n\\n1. Your departure city and destination city.\\n2. The exact dates or range of dates you're considering for your travel.\\n3. Your budget range.\\n4. Your preferences for accommodation (e.g., hotel, hostel, Airbnb).\\n5. If you need a rental car or if you're planning to use public transportation.\\n6. Any specific activities or attractions you're interested in, which could affect the location of your accommodation.\\n\\nWith these details, I can provide a more tailored and budget-friendly travel plan for you.\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"I want to travel over the summer within low budget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: El Brain introduces themselves to the AI, which responds by offering its assistance with a variety of tasks. El Brain asks for help with travel arrangements within the US, and the AI asks for more specific details such as departure and destination cities, preferred dates, and whether assistance is needed with flight bookings, hotel reservations, or car rentals. El Brain then specifies they want to travel over the summer on a low budget. The AI asks for further information including exact dates, budget range, accommodation preferences, transportation needs, and any specific activities or attractions of interest to provide a more tailored and budget-friendly travel plan.\n",
      "Human: I'm looking into cities in the mid west\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! The Midwest has a lot to offer in terms of culture, history, and natural beauty. Some popular cities to consider are Chicago, Illinois; Minneapolis, Minnesota; St. Louis, Missouri; and Indianapolis, Indiana. Each of these cities has its own unique attractions. For example, Chicago is known for its architecture, museums, and food scene; Minneapolis for its lakes and parks; St. Louis for the Gateway Arch and its breweries; and Indianapolis for the Indianapolis Motor Speedway and its vibrant arts scene.\\n\\nIf you could provide more details about what you're interested in, such as outdoor activities, historical sites, food and drink, arts and culture, or sports, I could help you narrow down your options and suggest specific attractions. Also, knowing your exact travel dates would help me check for any special events or festivals happening in these cities during your visit.\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"I'm looking into cities in the mid west\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice two things. The return object contain within the conversation chain is \"moving_summary_buffer\" rather than \"buffer\" AND the summary window is constrained to the 50 token limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Brain introduces themselves to the AI, which responds by offering its assistance with a variety of tasks. El Brain asks for help with travel arrangements within the US, and the AI asks for more specific details such as departure and destination cities, preferred dates, and whether assistance is needed with flight bookings, hotel reservations, or car rentals. El Brain then specifies they want to travel over the summer on a low budget. The AI asks for further information including exact dates, budget range, accommodation preferences, transportation needs, and any specific activities or attractions of interest to provide a more tailored and budget-friendly travel plan. El Brain expresses interest in visiting cities in the Midwest, and the AI suggests popular cities like Chicago, Minneapolis, St. Louis, and Indianapolis, each with its own unique attractions. The AI then asks for more details about El Brain's interests and exact travel dates to suggest specific attractions and check for special events or festivals.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_chain.memory.moving_summary_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great way to summarize memory with token limit. Let's look at alternative more algorithmically way to handle memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at Conversation Knowledge Graph Memory (ConversationKGMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of memory enforces use of specific information only presented in a section of the prompt (<u>history</u>) and provides a PromptTemplate to do the AI to do so.\n",
    "\n",
    "The intent is to <u>reduce hallucination and focus on specific context</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"The following is a conversation between and AI and a Human. The AI is helpful and provides specific details from its context.\n",
    "If the AI doesn't know an answer to the question, it responds with I don't know. \n",
    "The AI will only uses information contained in the Relevant information section and does not hallucinate.\n",
    "\n",
    "\n",
    "Relevant information\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation: \n",
    "Human: {input}\n",
    "AI:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we also instantiate the memory class with an llm (doesn't have to be gpt3.5 here, or before) just like with summary memory chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationKGMemory(llm=llm_openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all together into the conversation chain with the prompt we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_kgm = ConversationChain(\n",
    "    llm=llm_openai,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between and AI and a Human. The AI is helpful and provides specific details from its context.\n",
      "If the AI doesn't know an answer to the question, it responds with I don't know. \n",
      "The AI will only uses information contained in the Relevant information section and does not hallucinate.\n",
      "\n",
      "\n",
      "Relevant information\n",
      "\n",
      "\n",
      "\n",
      "Conversation: \n",
      "Human: Hi I'm El Brain\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello El Brain, how can I assist you today?'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_kgm.predict(input=\"Hi I'm El Brain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between and AI and a Human. The AI is helpful and provides specific details from its context.\n",
      "If the AI doesn't know an answer to the question, it responds with I don't know. \n",
      "The AI will only uses information contained in the Relevant information section and does not hallucinate.\n",
      "\n",
      "\n",
      "Relevant information\n",
      "\n",
      "\n",
      "\n",
      "Conversation: \n",
      "Human: I need help with travel arrengements in the US\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have any specific information about travel arrangements in the US.\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_kgm.predict(input=\"I need help with travel arrengements in the US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AI can't provide an answer to the request given that there is no associated context under the \"Relevant information\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between and AI and a Human. The AI is helpful and provides specific details from its context.\n",
      "If the AI doesn't know an answer to the question, it responds with I don't know. \n",
      "The AI will only uses information contained in the Relevant information section and does not hallucinate.\n",
      "\n",
      "\n",
      "Relevant information\n",
      "\n",
      "\n",
      "\n",
      "Conversation: \n",
      "Human: I'm not sure how I can book travel\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have any information on how to book travel.\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_kgm.predict(input=\"I'm not sure how I can book travel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try however providing context and relevant infornation it can work on to help identify an answer from relationships in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between and AI and a Human. The AI is helpful and provides specific details from its context.\n",
      "If the AI doesn't know an answer to the question, it responds with I don't know. \n",
      "The AI will only uses information contained in the Relevant information section and does not hallucinate.\n",
      "\n",
      "\n",
      "Relevant information\n",
      "\n",
      "\n",
      "\n",
      "Conversation: \n",
      "Human: My computer is broken and not turning on\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry to hear that. However, I need more information to help you troubleshoot the problem. Can you tell me what happens when you try to turn it on?\""
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_kgm.predict(input=\"My computer is broken and not turning on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between and AI and a Human. The AI is helpful and provides specific details from its context.\n",
      "If the AI doesn't know an answer to the question, it responds with I don't know. \n",
      "The AI will only uses information contained in the Relevant information section and does not hallucinate.\n",
      "\n",
      "\n",
      "Relevant information\n",
      "\n",
      "\n",
      "\n",
      "Conversation: \n",
      "Human: The screen is still black, it doesn't do the macOS sound like it usually does\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"It seems like your Mac is not starting up properly. Unfortunately, I don't have enough information to provide a specific solution. It could be a hardware issue or a software problem. You might want to try some general troubleshooting steps like checking the power source, trying a different display, or booting in safe mode.\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_kgm.predict(input=\"The screen is still black, it doesn't do the macOS sound like it usually does\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Knowledge Graph Memory (KGM) chain used provided text to identify a suitable answer by building a knolwedge graph. Let's look at the memory collected and the relationship between the entities as the KGM LLM tried to identify relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('El Brain', 'Human', 'is'),\n",
       " ('Human', 'travel arrangements in the US', 'needs help with'),\n",
       " ('My computer', 'broken', 'is'),\n",
       " ('My computer', 'turning on', 'is not'),\n",
       " (\"Human's computer\", 'black screen', 'has'),\n",
       " (\"Human's computer\", 'macOS startup sound', \"doesn't do\")]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_kgm.memory.kg.get_triples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be great to <u> identify the history stored object </u> it used for context but it was not initially apparent. We can however look at the memory exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hi I'm El Brain\", additional_kwargs={}, example=False),\n",
       " AIMessage(content='Hello El Brain, how can I assist you today?', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='I need help with travel arrengements in the US', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"I'm sorry, but I don't have any specific information about travel arrangements in the US.\", additional_kwargs={}, example=False),\n",
       " HumanMessage(content=\"I'm not sure how I can book travel\", additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"I'm sorry, but I don't have the specific information on how to book travel.\", additional_kwargs={}, example=False),\n",
       " HumanMessage(content='My computer is broken and not turning on', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"I'm sorry to hear that. However, I need more information to help you troubleshoot the problem. Can you tell me what happens when you try to turn it on?\", additional_kwargs={}, example=False),\n",
       " HumanMessage(content=\"The screen is still black, it doesn't do the macOS sound like it usually does\", additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"It seems like your Mac is not starting up properly. Try to perform a power cycle: shut it down completely and then turn it back on. If this doesn't work, you might need to try booting in safe mode or resetting the NVRAM/PRAM.\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_kgm.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly let's take a look at the Entity Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the standard template and its use of the <u>entities argument</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{entities}\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Last line:\n",
      "Human: {input}\n",
      "You:\n"
     ]
    }
   ],
   "source": [
    "print(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the converesation chain as usual with <u>ConversationChain</u>. Notice how we pass the template above (so an entities section is expected by the template prompt) and also an llm to support entity memory use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_entity = ConversationChain(\n",
    "    llm=llm_openai,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm_openai),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'El Brain': '', 'Gordo': ''}\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Last line:\n",
      "Human: Hi, I'm El Brain. My cat, his name is Gordo is he is hiding\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello El Brain! It's nice to meet you. Cats like Gordo often hide for a variety of reasons. It could be due to fear, stress, or simply because they found a new cozy spot. If Gordo is hiding more than usual, it might be a good idea to check if there are any changes in his environment that could be causing him stress. If he continues to hide and shows signs of distress or illness, it would be best to consult with a vet.\""
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_entity.predict(input=\"Hi, I'm El Brain. My cat, his name is Gordo is he is hiding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'B0456C7': ''}\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, I'm El Brain. My cat, his name is Gordo is he is hiding\n",
      "AI: Hello El Brain! It's nice to meet you. Cats like Gordo often hide for a variety of reasons. It could be due to fear, stress, or simply because they found a new cozy spot. If Gordo is hiding more than usual, it might be a good idea to check if there are any changes in his environment that could be causing him stress. If he continues to hide and shows signs of distress or illness, it would be best to consult with a vet.\n",
      "Last line:\n",
      "Human: How can I help him? His insurnace number is B0456C7\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To help Gordo feel more comfortable, you can try the following:\\n\\n1. **Create a Safe Space:** Make sure Gordo has a safe, quiet space where he can retreat to. This could be a specific room, a cat tree, or even a box. Cats often feel safer in elevated areas or enclosed spaces.\\n\\n2. **Minimize Stress:** Try to identify any potential sources of stress in Gordo's environment and minimize them if possible. This could include loud noises, unfamiliar people or animals, or changes in his routine.\\n\\n3. **Play and Interaction:** Spend quality time with Gordo. Play with him using his favorite toys. This can help build trust and make him feel more comfortable.\\n\\n4. **Familiar Scents:** Cats are very scent-oriented. You can try leaving items with your scent in his favorite hiding places to make him feel more secure.\\n\\n5. **Gradual Introduction:** If there are new elements in his environment (like a new pet or family member), introduce them gradually and always under positive circumstances.\\n\\nIf Gordo's behavior doesn't improve or if he shows signs of illness, it's important to consult with a vet. Since you've provided his insurance number B0456C7, you should be able to get him the care he needs. Remember, sudden changes in behavior can sometimes indicate a health issue, so it's always best to err on the side of caution.\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_entity.predict(input=\"How can I help him? His insurnace number is B0456C7\") # Might need to change this to include entity example!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By providing context to the Conversation Entity Memory Chain it can collect entities through the conversaion (review template) to get a sense of relevant specific subjects/topics that needs to capture. Below is the entity identified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B0456C7']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_entity.memory.entity_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{}\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, I'm El Brain. My cat, his name is Gordo is he is hiding\n",
      "AI: Hello El Brain! It's nice to meet you. Cats like Gordo often hide for a variety of reasons. It could be due to fear, stress, or simply because they found a new cozy spot. If Gordo is hiding more than usual, it might be a good idea to check if there are any changes in his environment that could be causing him stress. If he continues to hide and shows signs of distress or illness, it would be best to consult with a vet.\n",
      "Human: How can I help him? His insurnace number is B0456C7\n",
      "AI: To help Gordo feel more comfortable, you can try the following:\n",
      "\n",
      "1. **Create a Safe Space:** Make sure Gordo has a safe, quiet space where he can retreat to. This could be a specific room, a cat tree, or even a box. Cats often feel safer in elevated areas or enclosed spaces.\n",
      "\n",
      "2. **Minimize Stress:** Try to identify any potential sources of stress in Gordo's environment and minimize them if possible. This could include loud noises, unfamiliar people or animals, or changes in his routine.\n",
      "\n",
      "3. **Play and Interaction:** Spend quality time with Gordo. Play with him using his favorite toys. This can help build trust and make him feel more comfortable.\n",
      "\n",
      "4. **Familiar Scents:** Cats are very scent-oriented. You can try leaving items with your scent in his favorite hiding places to make him feel more secure.\n",
      "\n",
      "5. **Gradual Introduction:** If there are new elements in his environment (like a new pet or family member), introduce them gradually and always under positive circumstances.\n",
      "\n",
      "If Gordo's behavior doesn't improve or if he shows signs of illness, it's important to consult with a vet. Since you've provided his insurance number B0456C7, you should be able to get him the care he needs. Remember, sudden changes in behavior can sometimes indicate a health issue, so it's always best to err on the side of caution.\n",
      "Last line:\n",
      "Human: Can you help me contact the Vet?\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry for any confusion, but as an AI, I don't have the ability to make phone calls or send emails. However, I can guide you on how to do it. \\n\\nHere are the general steps to contact a vet:\\n\\n1. **Find the Contact Information:** Look up the contact information for your vet. This could be a phone number or an email address. It's usually available on their website.\\n\\n2. **Prepare Information:** Before you contact the vet, prepare all the necessary information. This includes Gordo's symptoms, any changes in behavior, and his insurance number (B0456C7).\\n\\n3. **Make the Call or Send the Email:** If you're calling, wait until you're connected to a representative or leave a voicemail with all the necessary information. If you're emailing, make sure to include all the information in a clear and concise manner.\\n\\n4. **Follow Their Instructions:** The vet or their representative will likely give you instructions on what to do next. This could include bringing Gordo in for a check-up, monitoring his behavior, or trying certain at-home remedies.\\n\\nRemember, it's important to contact your vet as soon as possible if you're concerned about Gordo's health.\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_entity.predict(input=\"Can you help me contact the Vet?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at all the entities and their context in the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store={'El Brain': 'El Brain is a person who has a cat named Gordo.', 'Gordo': \"Gordo is El Brain's cat who has a tendency to hide.\", 'B0456C7': \"B0456C7 is the insurance number for El Brain's cat, Gordo.\"}\n"
     ]
    }
   ],
   "source": [
    "print(conversation_entity.memory.entity_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up\n",
    "\n",
    "In this exercise we've taken a look at the different ways to incorporate memory chains in the interaction with LLMs. These have include simple interactions (<u>ConversationChain</u>) to more sophisticated approaches to optimally utilize token while retaining context in which summaries and maximum token buffer windows area allowed <u>ConversationSummaryBufferMemory</u>\n",
    "\n",
    "We can develop this further by incorporating PromptTemplates in our Playground noteboooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
