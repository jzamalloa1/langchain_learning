{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running HF Models through API and Locally in Langchain\n",
    "\n",
    "Here we (1) test the inference API from huggingface to call a model output running in the HF server and (2) learn how we can import that model and run it locally on our macchines. All compatible with Langchanin tools\n",
    "\n",
    "Inspiration taken from: https://www.youtube.com/watch?v=Kn7SX2Mx_Jk&list=PL8motc6AQftk1Bs42EW45kwYbyJ4jOdiZ&index=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReadMe material\n",
    "\n",
    "- [Inference in Large Language Models](https://medium.com/@andrew_johnson_4/understanding-inference-in-large-language-models-f4a4a4a736a5) - Insightful definition of text inference for LLMs (no need to pay for entire article, definition in first paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
