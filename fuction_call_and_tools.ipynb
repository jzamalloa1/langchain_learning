{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling & Custom Agent Tools\n",
    "\n",
    "Understanding differences and how to use them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, os, pprint\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import random\n",
    "from streamlit_jupyter import StreamlitPatcher\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.output_parsers import JsonOutputToolsParser, JsonOutputKeyToolsParser\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent, create_react_agent\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain import hub\n",
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "StreamlitPatcher().jupyter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling (Tool_Choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting a custom python function to an OpenAI function calling tool\n",
    "\n",
    "Requires specifying type of arguments, as well as description of function and each arguments. The python function will be converted by convert_to_openai_tool(). More info [here](https://python.langchain.com/docs/modules/model_io/chat/function_calling)\n",
    "\n",
    "**Note** Only functions are supported as tools by OpenAI. \"tool_choice\" controls if a tool should be used, and can force it to be used. More on this [here](https://platform.openai.com/docs/api-reference/chat/create#chat-create-tools)\n",
    "\n",
    "*tools* and *tool_choice* replace the deprecated *functions* and *function_calling*, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'create_matrix',\n",
       "  'description': 'Create a matrix of rows(r) by columns(c)',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'r': {'type': 'integer',\n",
       "     'description': 'First dimension of matrix'},\n",
       "    'c': {'type': 'integer', 'description': 'Second dimension of matrix'}},\n",
       "   'required': ['r', 'c']}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_matrix(r:int, c:int):\n",
    "    \"\"\"Create a matrix of rows(r) by columns(c)\n",
    "\n",
    "    Args:\n",
    "        r: First dimension of matrix\n",
    "        c: Second dimension of matrix\n",
    "    \"\"\"\n",
    "\n",
    "    m = np.random.randn(r, c)\n",
    "\n",
    "    return m\n",
    "\n",
    "convert_to_openai_tool(create_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"create_matrix\",\n",
      "    \"description\": \"Create a matrix of rows(r) by columns(c)\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"r\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"First dimension of matrix\"\n",
      "        },\n",
      "        \"c\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"Second dimension of matrix\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"r\",\n",
      "        \"c\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(json.dumps(convert_to_openai_tool(create_matrix), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing (\"Binding function) custom function call built in an LLM\n",
    "\n",
    "We'll incorporate the function call as part of our model so it is \"bound\" (**binding function**) and ready to be utilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0.1, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it without function calling. LLM will produce actual answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure, here's a random 3x5 matrix:\\n\\n\\\\[\\n\\\\begin{pmatrix}\\n7 & 3 & 5 & 2 & 8 \\\\\\\\\\n1 & 4 & 9 & 6 & 0 \\\\\\\\\\n2 & 7 & 8 & 3 & 4 \\\\\\\\\\n\\\\end{pmatrix}\\n\\\\]\\n\\nRemember, the numbers are randomly chosen, so they don't follow any specific pattern or rule.\")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result = llm.invoke(\"can you create a random 3x5 matrix?\")\n",
    "llm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that answer will be produced, but it will be produced as part of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here is a random 3x5 matrix:\\n\\n[[4, 7, 2, 9, 1],\\n [3, 8, 5, 6, 2],\\n [1, 9, 4, 7, 3]]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM with function calling will produce json input to pre-specified function (\"create_matrix()\" in function call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hSJ0FnN67g7Itf0A3ZkLfyb8', 'function': {'arguments': '{\"r\":3,\"c\":5}', 'name': 'create_matrix'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result_fc = llm.invoke(\"can you create a random 3x5 matrix?\", \n",
    "                        tools = [convert_to_openai_tool(create_matrix)])\n",
    "\n",
    "llm_result_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that content will be null, but this will be report json input ready to be passed to actual function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result_fc.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"r\":3,\"c\":5}\n",
      "create_pandas\n"
     ]
    }
   ],
   "source": [
    "print(llm_result_fc.additional_kwargs[\"tool_calls\"][0][\"function\"][\"name\"])\n",
    "print(llm_result_fc.additional_kwargs[\"tool_calls\"][0][\"function\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binding permanently attaches the function to the LLM so that we can invoke it without calling the function call every time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_EiUWczb5dViyT4Ls4m1g0Guk', 'function': {'arguments': '{\"r\":3,\"c\":5}', 'name': 'create_matrix'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_fc = llm.bind(tools = [convert_to_openai_tool(create_matrix)])\n",
    "llm_fc.invoke(\"can you create a random 3x5 matrix?\") #Same answer as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example the regular llm was able to produce an answer for a simple request, but what would happen with a more complex request?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! Here is an example code to create a pandas dataframe of size 3x5 with random numbers:\\n\\n```python\\nimport pandas as pd\\nimport numpy as np\\n\\ndata = np.random.randint(0, 100, size=(3, 5))\\ndf = pd.DataFrame(data, columns=['A', 'B', 'C', 'D', 'E'])\\n\\nprint(df)\\n```\\n\\nThis code will create a pandas dataframe with 3 rows and 5 columns filled with random numbers between 0 and 100.\")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result = llm.invoke(\"can you create a pandas dataframe of 3x5 with random numbers?\")\n",
    "llm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is an example code to create a pandas dataframe of size 3x5 with random numbers:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "data = np.random.randint(0, 100, size=(3, 5))\n",
      "df = pd.DataFrame(data, columns=['A', 'B', 'C', 'D', 'E'])\n",
      "\n",
      "print(df)\n",
      "```\n",
      "\n",
      "This code will create a pandas dataframe with 3 rows and 5 columns filled with random numbers between 0 and 100.\n"
     ]
    }
   ],
   "source": [
    "print(llm_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"create_pandas\",\n",
      "    \"description\": \"Create a pandas dataframe of random numbers of rows(r) by columns(c)\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"r\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"First dimension of pandas dataframe\"\n",
      "        },\n",
      "        \"c\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"Second dimension of pandas dataframe\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"r\",\n",
      "        \"c\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def create_pandas(r:int, c:int):\n",
    "    \"\"\"Create a pandas dataframe of random numbers of rows(r) by columns(c)\n",
    "\n",
    "    Args:\n",
    "        r: First dimension of pandas dataframe\n",
    "        c: Second dimension of pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    m  = np.random.randn(r, c)\n",
    "    df = pd.DataFrame(m, columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "print(json.dumps(convert_to_openai_tool(create_pandas), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ecz0zRIuBdKKSunS9rPGAcsI', 'function': {'arguments': '{\"r\":3,\"c\":5}', 'name': 'create_pandas'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result_fc = llm.invoke(\"can you create a pandas dataframe of 3x5 with random numbers?\", \n",
    "                        tools = [convert_to_openai_tool(create_pandas)])\n",
    "\n",
    "llm_result_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_pandas\n",
      "{\"r\":3,\"c\":5}\n"
     ]
    }
   ],
   "source": [
    "print(llm_result_fc.additional_kwargs[\"tool_calls\"][0][\"function\"][\"name\"])\n",
    "print(llm_result_fc.additional_kwargs[\"tool_calls\"][0][\"function\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK....how about something much more complex, like a figure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! Here is an example code to create a Streamlit line chart with 2 lines showing random numbers going from 0 to 100:\\n\\n```python\\nimport streamlit as st\\nimport pandas as pd\\nimport numpy as np\\n\\n# Generate random data\\ndata = pd.DataFrame({\\n    'x': np.arange(0, 101),\\n    'y1': np.random.randint(0, 101, size=101),\\n    'y2': np.random.randint(0, 101, size=101)\\n})\\n\\n# Create line chart\\nst.line_chart(data[['y1', 'y2']])\\n```\\n\\nYou can run this code in a Python environment with Streamlit installed to see the line chart with 2 lines showing random numbers.\")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result = llm.invoke(\"can you create a streamlit linechart showing 2 lines with random numbers going from 0 to 100?\")\n",
    "llm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is an example code to create a Streamlit line chart with 2 lines showing random numbers going from 0 to 100:\n",
      "\n",
      "```python\n",
      "import streamlit as st\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# Generate random data\n",
      "data = pd.DataFrame({\n",
      "    'x': np.arange(0, 101),\n",
      "    'y1': np.random.randint(0, 101, size=101),\n",
      "    'y2': np.random.randint(0, 101, size=101)\n",
      "})\n",
      "\n",
      "# Create line chart\n",
      "st.line_chart(data[['y1', 'y2']])\n",
      "```\n",
      "\n",
      "You can run this code in a Python environment with Streamlit installed to see the line chart with 2 lines showing random numbers.\n"
     ]
    }
   ],
   "source": [
    "print(llm_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"create_streamlit_lines\",\n",
      "    \"description\": \"Create a streamlit linechart of n number of lines\\nof a random distribution of d numbers with the lowest number \\nbeing higher or equal to l_range\\nand the highest number being lower or equal to h_range\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"n\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"number of lines\"\n",
      "        },\n",
      "        \"d\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"sample size of distribution\"\n",
      "        },\n",
      "        \"l_range\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"lowest number of lines random distribution\"\n",
      "        },\n",
      "        \"h_range\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"highest number of lines random distribution\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"n\",\n",
      "        \"d\",\n",
      "        \"l_range\",\n",
      "        \"h_range\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def create_streamlit_lines(n:int, d:int, l_range:int, h_range:int):\n",
    "    \"\"\"Create a streamlit linechart of n number of lines\n",
    "    of a random distribution of d numbers with the lowest number \n",
    "    being higher or equal to l_range\n",
    "    and the highest number being lower or equal to h_range\n",
    "\n",
    "    Args:\n",
    "        n: number of lines\n",
    "        d: sample size of distribution\n",
    "        l_range: lowest number of lines random distribution\n",
    "        h_range: highest number of lines random distribution\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import streamlit as st\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'x': np.arange(0, d),\n",
    "        'y1': np.random.randint(l_range, h_range, size=d),\n",
    "        'y2': np.random.randint(l_range, h_range, size=d)\n",
    "    })\n",
    "\n",
    "    plot = st.line_chart(df[['y1', 'y2']])\n",
    "\n",
    "    return(plot)\n",
    "\n",
    "print(json.dumps(convert_to_openai_tool(create_streamlit_lines), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BTT5GxtClxWgi3msHs8vSoo3', 'function': {'arguments': '{\"n\": 2, \"d\": 10, \"l_range\": 1, \"h_range\": 10}', 'name': 'create_streamlit_lines'}, 'type': 'function'}, {'id': 'call_wAHV1JZIrJiNzg8CD31wbZY3', 'function': {'arguments': '{\"n\": 2, \"d\": 10, \"l_range\": 1, \"h_range\": 10}', 'name': 'create_streamlit_lines'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result_fc = llm.invoke(\"Create a streamlit figure containing 2 lines, each line being of size 10\", \n",
    "                        tools = [convert_to_openai_tool(create_streamlit_lines)])\n",
    "\n",
    "llm_result_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_streamlit_lines\n",
      "{\"n\": 2, \"d\": 10, \"l_range\": 1, \"h_range\": 10}\n"
     ]
    }
   ],
   "source": [
    "print(llm_result_fc.additional_kwargs[\"tool_calls\"][0][\"function\"][\"name\"])\n",
    "print(llm_result_fc.additional_kwargs[\"tool_calls\"][0][\"function\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen the function caller does a pretty good job at it, in numpy, pandas and more complex streamlit function calls. **Even when not having all arguments provided by the user, it makes pretty decent assumptions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to function call, we'll dive next into actually using the tools, and passing the arguments to the tools that the LLM function calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Use\n",
    "\n",
    "Inspiration from [here](https://python.langchain.com/docs/use_cases/tool_use/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **two ways** to interface(*invoke*) with tools.\n",
    "\n",
    "1. With a *chain* for pre-defined sequence of tool usage:\n",
    "\n",
    "<p>\n",
    "<img src=\"ILLUSTRATIONS/tool_chain_sequence_diagram.svg\" \n",
    "      width=\"65%\" height=\"auto\"\n",
    "      style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "2. With an *agent loop* so the agent decides how many times to use the tool:\n",
    "\n",
    "<p>\n",
    "<img src=\"ILLUSTRATIONS/tool_agent_loop_diagram.svg\" \n",
    "      width=\"65%\" height=\"auto\"\n",
    "      style=\"display: block; margin: 0 auto\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Let's explore the first one, **Tool Chain** for pre-defined usage of a tool. \n",
    "\n",
    "We'll create a custom tool first using the *tool decorator* on the plotly express dataset\n",
    "\n",
    "<p>\n",
    "<img src=\"ILLUSTRATIONS/tool_chain_sequence_diagram.svg\" \n",
    "      width=\"45%\" height=\"auto\"\n",
    "      style=\"display: block; margin: 0 auto\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to develop a tool which can create histograms of pre-defined columns. We'll use the plotly express as an example. For reference the native OpenAI llm does not produce an accurate response..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"import plotly.express as px\\n\\nfig = px.line(stocks, x='Date', y='Close', color='Stock')\\nfig.show()\")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Create a linechart with the stocks dataframe from plotly express comparing the stock price over time of GOOG and APPL with a different color per stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def px_trend_compare(data:str, col1:str, col2:str):\n",
    "    \"\"\"Creates a line chart using plotly of two columns\n",
    "    'col1' and 'col2,' which are two stock market ticker symbols,\n",
    "    tracking their value over time. The data is\n",
    "    available in 'data' stored in plotly express.\n",
    "    Assign a different color for each line 'col1' and 'col2.'\n",
    "\n",
    "    Args:\n",
    "        data: Table name in plotly express\n",
    "        col1: Stock market ticker symbol\n",
    "        col2: Another stock market ticker symbol\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    import plotly.express as px\n",
    "\n",
    "    data_module = getattr(px.data, data)\n",
    "    df = data_module()\n",
    "\n",
    "    df = (df\n",
    "          .melt(id_vars=\"date\", value_vars=[col1, col2])\n",
    "    )\n",
    "\n",
    "    fig = px.line(df, x='date', y='value', color='variable')\n",
    "    \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>FB</th>\n",
       "      <th>NFLX</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>1.018172</td>\n",
       "      <td>1.011943</td>\n",
       "      <td>1.061881</td>\n",
       "      <td>0.959968</td>\n",
       "      <td>1.053526</td>\n",
       "      <td>1.015988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>1.032008</td>\n",
       "      <td>1.019771</td>\n",
       "      <td>1.053240</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>1.049860</td>\n",
       "      <td>1.020524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>1.066783</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>1.140676</td>\n",
       "      <td>1.016858</td>\n",
       "      <td>1.307681</td>\n",
       "      <td>1.066561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>1.008773</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>1.163374</td>\n",
       "      <td>1.018357</td>\n",
       "      <td>1.273537</td>\n",
       "      <td>1.040708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>1.216280</td>\n",
       "      <td>1.546914</td>\n",
       "      <td>1.425061</td>\n",
       "      <td>1.075997</td>\n",
       "      <td>1.463641</td>\n",
       "      <td>1.720717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2019-12-09</td>\n",
       "      <td>1.222821</td>\n",
       "      <td>1.572286</td>\n",
       "      <td>1.432660</td>\n",
       "      <td>1.038855</td>\n",
       "      <td>1.421496</td>\n",
       "      <td>1.752239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>1.224418</td>\n",
       "      <td>1.596800</td>\n",
       "      <td>1.453455</td>\n",
       "      <td>1.104094</td>\n",
       "      <td>1.604362</td>\n",
       "      <td>1.784896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>1.226504</td>\n",
       "      <td>1.656000</td>\n",
       "      <td>1.521226</td>\n",
       "      <td>1.113728</td>\n",
       "      <td>1.567170</td>\n",
       "      <td>1.802472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1.213014</td>\n",
       "      <td>1.678000</td>\n",
       "      <td>1.503360</td>\n",
       "      <td>1.098475</td>\n",
       "      <td>1.540883</td>\n",
       "      <td>1.788185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      GOOG      AAPL      AMZN        FB      NFLX      MSFT\n",
       "0    2018-01-01  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "1    2018-01-08  1.018172  1.011943  1.061881  0.959968  1.053526  1.015988\n",
       "2    2018-01-15  1.032008  1.019771  1.053240  0.970243  1.049860  1.020524\n",
       "3    2018-01-22  1.066783  0.980057  1.140676  1.016858  1.307681  1.066561\n",
       "4    2018-01-29  1.008773  0.917143  1.163374  1.018357  1.273537  1.040708\n",
       "..          ...       ...       ...       ...       ...       ...       ...\n",
       "100  2019-12-02  1.216280  1.546914  1.425061  1.075997  1.463641  1.720717\n",
       "101  2019-12-09  1.222821  1.572286  1.432660  1.038855  1.421496  1.752239\n",
       "102  2019-12-16  1.224418  1.596800  1.453455  1.104094  1.604362  1.784896\n",
       "103  2019-12-23  1.226504  1.656000  1.521226  1.113728  1.567170  1.802472\n",
       "104  2019-12-30  1.213014  1.678000  1.503360  1.098475  1.540883  1.788185\n",
       "\n",
       "[105 rows x 7 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px.data.stocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now a **custom tool we can call in Langchain** with its own properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "px_trend_compare\n",
      "px_trend_compare(data: str, col1: str, col2: str) - Creates a line chart using plotly of two columns\n",
      "    'col1' and 'col2,' which are two stock market ticker symbols,\n",
      "    tracking their value over time. The data is\n",
      "    available in 'data' stored in plotly express.\n",
      "    Assign a different color for each line 'col1' and 'col2.'\n",
      "\n",
      "    Args:\n",
      "        data: Table name in plotly express\n",
      "        col1: Stock market ticker symbol\n",
      "        col2: Another stock market ticker symbol\n",
      "{'data': {'title': 'Data', 'type': 'string'}, 'col1': {'title': 'Col1', 'type': 'string'}, 'col2': {'title': 'Col2', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(px_trend_compare.name)\n",
    "print(px_trend_compare.description)\n",
    "print(px_trend_compare.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out our plotting tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=GOOG<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "GOOG",
         "line": {
          "color": "#000001",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "GOOG",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.018172278347936,
          1.032007866452698,
          1.066782783389724,
          1.0087731636550117,
          0.9415276737437316,
          0.99325918262539,
          1.0222821547641083,
          0.9788520214265992,
          1.0524482730908842,
          1.0303929312465263,
          0.926821104067592,
          0.9360932452590338,
          0.913638710861412,
          0.93380695379017,
          0.9734447261178653,
          0.9345146364100892,
          0.9509902470625956,
          0.9963982380519172,
          0.9674568868105002,
          0.9758943718805396,
          1.015668254641377,
          1.0169111849053498,
          1.0453898287179595,
          1.0483111519067918,
          1.0121753574512644,
          1.0344211867653972,
          1.0785588920381208,
          1.075011617811375,
          1.1236312044424703,
          1.1102129167272332,
          1.1228237368393843,
          1.0895729410299655,
          1.1074367837463466,
          1.1052048693141154,
          1.0567939333314087,
          1.0637798374890872,
          1.0579370795194665,
          1.0827776350267664,
          1.0500077089175164,
          1.007121903906116,
          0.9947651405743836,
          0.9720929301886708,
          0.959681788913054,
          0.9672663993407256,
          0.9630385756700248,
          0.9289168536315806,
          0.992923504040418,
          0.9404389054995582,
          0.945446952912676,
          0.8886892896888904,
          0.9408925313390586,
          0.9714034098401132,
          0.9591373489949891,
          0.9963982380519172,
          0.989802500200548,
          1.0077298024501202,
          0.9934950771344468,
          1.0103608540932627,
          1.0073850422758417,
          1.035165084150587,
          1.0363716889645844,
          1.0746032883264525,
          1.0936918990354445,
          1.064487521016258,
          1.095188886079836,
          1.1049145977684258,
          1.1216987538299403,
          1.1541874899828073,
          1.075456162061569,
          1.0562859304552756,
          1.0544986709579427,
          1.0283425342867192,
          1.001270175031893,
          0.9671666152648106,
          0.98468558802946,
          1.0178275181736574,
          0.980657443195294,
          1.0266368965939394,
          1.0387124690620373,
          1.025285100664745,
          1.1344366027859267,
          1.0832494231376286,
          1.0778240762422375,
          1.068379555417282,
          1.0445098208996275,
          1.0779056980467905,
          1.0931748145700046,
          1.12459294475006,
          1.115856106545024,
          1.1114649285805127,
          1.0968672799119472,
          1.10271900878617,
          1.129972884606169,
          1.1477913211905195,
          1.155602744537941,
          1.189742629754999,
          1.2110630442115171,
          1.1751993590303178,
          1.183927115646047,
          1.216279741365772,
          1.222820990588552,
          1.22441776261611,
          1.2265044859331442,
          1.213013658002661
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=AMZN<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "AMZN",
         "line": {
          "color": "#000002",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "AMZN",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.0618806117055757,
          1.0532404284307677,
          1.1406756202628388,
          1.1633743377885228,
          1.0898676795580526,
          1.1786207619316666,
          1.2203654438831366,
          1.2205688381237838,
          1.284548542665418,
          1.2786826844946546,
          1.2167532101702832,
          1.1775224533715958,
          1.1432627388670606,
          1.16405781403187,
          1.242730666448932,
          1.2794473988384474,
          1.2862244591394254,
          1.3040906767647622,
          1.2808711585229775,
          1.3099809658381354,
          1.3355191588974509,
          1.3700554610940725,
          1.3960736368996989,
          1.3958296232020404,
          1.3829181608736414,
          1.391729163581091,
          1.4750394640760272,
          1.4755844971819587,
          1.4784890230752108,
          1.4833867718479574,
          1.5346502643964448,
          1.5313308069300795,
          1.5501814209506477,
          1.637494456642517,
          1.5881591374274802,
          1.6029011479217037,
          1.5580080272628667,
          1.6295946560652816,
          1.5373757268816928,
          1.4551718788522234,
          1.435174192909178,
          1.3365524179114776,
          1.3550368620941855,
          1.3931936419790223,
          1.2963616956201691,
          1.22204146042711,
          1.375083410656027,
          1.3254226411301075,
          1.295141330176286,
          1.1206615472526131,
          1.202483038516975,
          1.2817010232963573,
          1.334721869745653,
          1.3799892040777797,
          1.359137222458745,
          1.3230632475991762,
          1.2921391799289847,
          1.3081910371293215,
          1.3273996770823542,
          1.3600809993969647,
          1.3186455808291295,
          1.393136635454831,
          1.435776232539301,
          1.4487771761299302,
          1.4947687054188046,
          1.4994712046698764,
          1.5146280474808236,
          1.5869876346023932,
          1.596612214272432,
          1.537644171481961,
          1.5205753430783882,
          1.483378627942562,
          1.44415601504927,
          1.4677172714127285,
          1.521120475440709,
          1.5549896884611636,
          1.540613747734834,
          1.58070684404494,
          1.6361032717659916,
          1.5982882308164057,
          1.5808207570233568,
          1.4833460531345568,
          1.4706054102388,
          1.4583936118945735,
          1.4234505212166575,
          1.445148654606286,
          1.491701504811883,
          1.4964446227063888,
          1.4596872708598625,
          1.4037863302335007,
          1.4153391824933792,
          1.4090502488441077,
          1.4298696556551374,
          1.43297747571907,
          1.4574742658589632,
          1.452950830015895,
          1.4152089825177483,
          1.420277551536714,
          1.465089434095106,
          1.425061388144621,
          1.4326601685000062,
          1.4534552436648156,
          1.52122624451373,
          1.503360026888393
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "candlestick": [
           {
            "decreasing": {
             "line": {
              "color": "#000033"
             }
            },
            "increasing": {
             "line": {
              "color": "#000032"
             }
            },
            "type": "candlestick"
           }
          ],
          "contour": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram2d": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "icicle": [
           {
            "textfont": {
             "color": "white"
            },
            "type": "icicle"
           }
          ],
          "sankey": [
           {
            "textfont": {
             "color": "#000036"
            },
            "type": "sankey"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "width": 0
             }
            },
            "type": "scatter"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#000038"
             },
             "font": {
              "color": "#000037"
             },
             "line": {
              "color": "#000039"
             }
            },
            "header": {
             "fill": {
              "color": "#000040"
             },
             "font": {
              "color": "#000036"
             },
             "line": {
              "color": "#000039"
             }
            },
            "type": "table"
           }
          ],
          "waterfall": [
           {
            "connector": {
             "line": {
              "color": "#000036",
              "width": 2
             }
            },
            "decreasing": {
             "marker": {
              "color": "#000033"
             }
            },
            "increasing": {
             "marker": {
              "color": "#000032"
             }
            },
            "totals": {
             "marker": {
              "color": "#000034"
             }
            },
            "type": "waterfall"
           }
          ]
         },
         "layout": {
          "coloraxis": {
           "colorscale": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#000021"
            ],
            [
             0.1,
             "#000022"
            ],
            [
             0.2,
             "#000023"
            ],
            [
             0.3,
             "#000024"
            ],
            [
             0.4,
             "#000025"
            ],
            [
             0.5,
             "#000026"
            ],
            [
             0.6,
             "#000027"
            ],
            [
             0.7,
             "#000028"
            ],
            [
             0.8,
             "#000029"
            ],
            [
             0.9,
             "#000030"
            ],
            [
             1,
             "#000031"
            ]
           ],
           "sequential": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorway": [
           "#000001",
           "#000002",
           "#000003",
           "#000004",
           "#000005",
           "#000006",
           "#000007",
           "#000008",
           "#000009",
           "#000010"
          ]
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px_trend_compare.invoke(\n",
    "    {\"data\":\"stocks\", \"col1\":\"GOOG\", \"col2\":\"AMZN\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works like a charm!! Let's now use **function calling** to **bind** and convert our Langchain tool to a function call. Binding it to our LLM will make it callable all the time. *We can also enfore it by passing the argument 'tool_choice'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_px_stocks = llm.bind_tools([px_trend_compare], tool_choice=\"px_trend_compare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is an LLM-bound function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'px_trend_compare',\n",
       "   'description': \"px_trend_compare(data: str, col1: str, col2: str) - Creates a line chart using plotly of two columns\\n    'col1' and 'col2,' which are two stock market ticker symbols,\\n    tracking their value over time. The data is\\n    available in 'data' stored in plotly express.\\n    Assign a different color for each line 'col1' and 'col2.'\\n\\n    Args:\\n        data: Table name in plotly express\\n        col1: Stock market ticker symbol\\n        col2: Another stock market ticker symbol\",\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'data': {'type': 'string'},\n",
       "     'col1': {'type': 'string'},\n",
       "     'col2': {'type': 'string'}},\n",
       "    'required': ['data', 'col1', 'col2']}}}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_px_stocks.kwargs[\"tools\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(convert_to_openai_tool(create_matrix), indent=2))\n",
    "# print(json.dumps(convert_to_openai_tool(px_trend_compare), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function', 'function': {'name': 'px_trend_compare'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_px_stocks.kwargs[\"tool_choice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calling works well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bdNgkcUxgS49flHb8bdD9wfQ', 'function': {'arguments': '{\"data\":\"stocks\",\"col1\":\"GOOG\",\"col2\":\"AMZN\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_px_stocks.invoke(\"can you use the stocks dataframe in plotly express to generate a line graph comparing the stocks GOOG and AMZN?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll simply this response and add a JSON output parsers to convert this to a simple list. We'll start this chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = llm_px_stocks | JsonOutputToolsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'px_trend_compare',\n",
       "  'args': {'data': 'stocks', 'col1': 'GOOG', 'col2': 'AMZN'}}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(\"can you use the stocks dataframe in plotly express to generate a line graph comparing the stocks GOOG and AMZN?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** If we know for certain we'll be **invoking** our px_trend_compare tool to answer this function call, we can specify to only return its arguments in our **JsonOutputKeyToolParser** and request to only retun the first element of a potential list of many tool invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'stocks', 'col1': 'GOOG', 'col2': 'AMZN'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = llm_px_stocks | JsonOutputKeyToolsParser(\n",
    "    key_name=\"px_trend_compare\", return_single=True\n",
    ")\n",
    "\n",
    "llm_chain.invoke(\"can you use the stocks dataframe in plotly express to generate a line graph comparing the stocks GOOG and AMZN?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we have the specific function call return in a simple (digestable) format (get tool invocation), we can finally **call the tool** to be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=GOOG<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "GOOG",
         "line": {
          "color": "#000001",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "GOOG",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.018172278347936,
          1.032007866452698,
          1.066782783389724,
          1.0087731636550117,
          0.9415276737437316,
          0.99325918262539,
          1.0222821547641083,
          0.9788520214265992,
          1.0524482730908842,
          1.0303929312465263,
          0.926821104067592,
          0.9360932452590338,
          0.913638710861412,
          0.93380695379017,
          0.9734447261178653,
          0.9345146364100892,
          0.9509902470625956,
          0.9963982380519172,
          0.9674568868105002,
          0.9758943718805396,
          1.015668254641377,
          1.0169111849053498,
          1.0453898287179595,
          1.0483111519067918,
          1.0121753574512644,
          1.0344211867653972,
          1.0785588920381208,
          1.075011617811375,
          1.1236312044424703,
          1.1102129167272332,
          1.1228237368393843,
          1.0895729410299655,
          1.1074367837463466,
          1.1052048693141154,
          1.0567939333314087,
          1.0637798374890872,
          1.0579370795194665,
          1.0827776350267664,
          1.0500077089175164,
          1.007121903906116,
          0.9947651405743836,
          0.9720929301886708,
          0.959681788913054,
          0.9672663993407256,
          0.9630385756700248,
          0.9289168536315806,
          0.992923504040418,
          0.9404389054995582,
          0.945446952912676,
          0.8886892896888904,
          0.9408925313390586,
          0.9714034098401132,
          0.9591373489949891,
          0.9963982380519172,
          0.989802500200548,
          1.0077298024501202,
          0.9934950771344468,
          1.0103608540932627,
          1.0073850422758417,
          1.035165084150587,
          1.0363716889645844,
          1.0746032883264525,
          1.0936918990354445,
          1.064487521016258,
          1.095188886079836,
          1.1049145977684258,
          1.1216987538299403,
          1.1541874899828073,
          1.075456162061569,
          1.0562859304552756,
          1.0544986709579427,
          1.0283425342867192,
          1.001270175031893,
          0.9671666152648106,
          0.98468558802946,
          1.0178275181736574,
          0.980657443195294,
          1.0266368965939394,
          1.0387124690620373,
          1.025285100664745,
          1.1344366027859267,
          1.0832494231376286,
          1.0778240762422375,
          1.068379555417282,
          1.0445098208996275,
          1.0779056980467905,
          1.0931748145700046,
          1.12459294475006,
          1.115856106545024,
          1.1114649285805127,
          1.0968672799119472,
          1.10271900878617,
          1.129972884606169,
          1.1477913211905195,
          1.155602744537941,
          1.189742629754999,
          1.2110630442115171,
          1.1751993590303178,
          1.183927115646047,
          1.216279741365772,
          1.222820990588552,
          1.22441776261611,
          1.2265044859331442,
          1.213013658002661
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=AMZN<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "AMZN",
         "line": {
          "color": "#000002",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "AMZN",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.0618806117055757,
          1.0532404284307677,
          1.1406756202628388,
          1.1633743377885228,
          1.0898676795580526,
          1.1786207619316666,
          1.2203654438831366,
          1.2205688381237838,
          1.284548542665418,
          1.2786826844946546,
          1.2167532101702832,
          1.1775224533715958,
          1.1432627388670606,
          1.16405781403187,
          1.242730666448932,
          1.2794473988384474,
          1.2862244591394254,
          1.3040906767647622,
          1.2808711585229775,
          1.3099809658381354,
          1.3355191588974509,
          1.3700554610940725,
          1.3960736368996989,
          1.3958296232020404,
          1.3829181608736414,
          1.391729163581091,
          1.4750394640760272,
          1.4755844971819587,
          1.4784890230752108,
          1.4833867718479574,
          1.5346502643964448,
          1.5313308069300795,
          1.5501814209506477,
          1.637494456642517,
          1.5881591374274802,
          1.6029011479217037,
          1.5580080272628667,
          1.6295946560652816,
          1.5373757268816928,
          1.4551718788522234,
          1.435174192909178,
          1.3365524179114776,
          1.3550368620941855,
          1.3931936419790223,
          1.2963616956201691,
          1.22204146042711,
          1.375083410656027,
          1.3254226411301075,
          1.295141330176286,
          1.1206615472526131,
          1.202483038516975,
          1.2817010232963573,
          1.334721869745653,
          1.3799892040777797,
          1.359137222458745,
          1.3230632475991762,
          1.2921391799289847,
          1.3081910371293215,
          1.3273996770823542,
          1.3600809993969647,
          1.3186455808291295,
          1.393136635454831,
          1.435776232539301,
          1.4487771761299302,
          1.4947687054188046,
          1.4994712046698764,
          1.5146280474808236,
          1.5869876346023932,
          1.596612214272432,
          1.537644171481961,
          1.5205753430783882,
          1.483378627942562,
          1.44415601504927,
          1.4677172714127285,
          1.521120475440709,
          1.5549896884611636,
          1.540613747734834,
          1.58070684404494,
          1.6361032717659916,
          1.5982882308164057,
          1.5808207570233568,
          1.4833460531345568,
          1.4706054102388,
          1.4583936118945735,
          1.4234505212166575,
          1.445148654606286,
          1.491701504811883,
          1.4964446227063888,
          1.4596872708598625,
          1.4037863302335007,
          1.4153391824933792,
          1.4090502488441077,
          1.4298696556551374,
          1.43297747571907,
          1.4574742658589632,
          1.452950830015895,
          1.4152089825177483,
          1.420277551536714,
          1.465089434095106,
          1.425061388144621,
          1.4326601685000062,
          1.4534552436648156,
          1.52122624451373,
          1.503360026888393
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "candlestick": [
           {
            "decreasing": {
             "line": {
              "color": "#000033"
             }
            },
            "increasing": {
             "line": {
              "color": "#000032"
             }
            },
            "type": "candlestick"
           }
          ],
          "contour": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram2d": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "icicle": [
           {
            "textfont": {
             "color": "white"
            },
            "type": "icicle"
           }
          ],
          "sankey": [
           {
            "textfont": {
             "color": "#000036"
            },
            "type": "sankey"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "width": 0
             }
            },
            "type": "scatter"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#000038"
             },
             "font": {
              "color": "#000037"
             },
             "line": {
              "color": "#000039"
             }
            },
            "header": {
             "fill": {
              "color": "#000040"
             },
             "font": {
              "color": "#000036"
             },
             "line": {
              "color": "#000039"
             }
            },
            "type": "table"
           }
          ],
          "waterfall": [
           {
            "connector": {
             "line": {
              "color": "#000036",
              "width": 2
             }
            },
            "decreasing": {
             "marker": {
              "color": "#000033"
             }
            },
            "increasing": {
             "marker": {
              "color": "#000032"
             }
            },
            "totals": {
             "marker": {
              "color": "#000034"
             }
            },
            "type": "waterfall"
           }
          ]
         },
         "layout": {
          "coloraxis": {
           "colorscale": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#000021"
            ],
            [
             0.1,
             "#000022"
            ],
            [
             0.2,
             "#000023"
            ],
            [
             0.3,
             "#000024"
            ],
            [
             0.4,
             "#000025"
            ],
            [
             0.5,
             "#000026"
            ],
            [
             0.6,
             "#000027"
            ],
            [
             0.7,
             "#000028"
            ],
            [
             0.8,
             "#000029"
            ],
            [
             0.9,
             "#000030"
            ],
            [
             1,
             "#000031"
            ]
           ],
           "sequential": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorway": [
           "#000001",
           "#000002",
           "#000003",
           "#000004",
           "#000005",
           "#000006",
           "#000007",
           "#000008",
           "#000009",
           "#000010"
          ]
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_chain = (\n",
    "    llm_px_stocks\n",
    "    | JsonOutputKeyToolsParser(\n",
    "        key_name=\"px_trend_compare\", \n",
    "        return_single=True)\n",
    "    | px_trend_compare \n",
    ")\n",
    "\n",
    "llm_chain.invoke(\"can you use the stocks dataframe in plotly express to generate a line graph comparing the stocks GOOG and AMZN?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We were able to bind a tool to an LLM, and invoke the tool to get a graphical output from ChatOpenAI** Let's try the Agent path now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Let's explore the second option, **Agents** letting an agent decide how many times and when to use a tool \n",
    "\n",
    "We'll build a couple of tools for this and use the OpenAI tool agent which is compatible with the OpenAI tool calling API. **Agents allow multi-tool use.**\n",
    "\n",
    "<p>\n",
    "<img src=\"ILLUSTRATIONS/tool_agent_loop_diagram.svg\" \n",
    "      width=\"45%\" height=\"auto\"\n",
    "      style=\"display: block; margin: 0 auto\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a generic prompt from the langchain hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build our tools. We'll repurpose our *px_trend_compare* tool above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [px_trend_compare]\n",
    "# tools = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll construct the Tools agent and the Agent executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `px_trend_compare` with `{'col1': 'GOOG', 'col2': 'AMZN', 'data': 'stocks'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=GOOG<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "GOOG",
         "line": {
          "color": "#000001",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "GOOG",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.018172278347936,
          1.032007866452698,
          1.066782783389724,
          1.0087731636550117,
          0.9415276737437316,
          0.99325918262539,
          1.0222821547641083,
          0.9788520214265992,
          1.0524482730908842,
          1.0303929312465263,
          0.926821104067592,
          0.9360932452590338,
          0.913638710861412,
          0.93380695379017,
          0.9734447261178653,
          0.9345146364100892,
          0.9509902470625956,
          0.9963982380519172,
          0.9674568868105002,
          0.9758943718805396,
          1.015668254641377,
          1.0169111849053498,
          1.0453898287179595,
          1.0483111519067918,
          1.0121753574512644,
          1.0344211867653972,
          1.0785588920381208,
          1.075011617811375,
          1.1236312044424703,
          1.1102129167272332,
          1.1228237368393843,
          1.0895729410299655,
          1.1074367837463466,
          1.1052048693141154,
          1.0567939333314087,
          1.0637798374890872,
          1.0579370795194665,
          1.0827776350267664,
          1.0500077089175164,
          1.007121903906116,
          0.9947651405743836,
          0.9720929301886708,
          0.959681788913054,
          0.9672663993407256,
          0.9630385756700248,
          0.9289168536315806,
          0.992923504040418,
          0.9404389054995582,
          0.945446952912676,
          0.8886892896888904,
          0.9408925313390586,
          0.9714034098401132,
          0.9591373489949891,
          0.9963982380519172,
          0.989802500200548,
          1.0077298024501202,
          0.9934950771344468,
          1.0103608540932627,
          1.0073850422758417,
          1.035165084150587,
          1.0363716889645844,
          1.0746032883264525,
          1.0936918990354445,
          1.064487521016258,
          1.095188886079836,
          1.1049145977684258,
          1.1216987538299403,
          1.1541874899828073,
          1.075456162061569,
          1.0562859304552756,
          1.0544986709579427,
          1.0283425342867192,
          1.001270175031893,
          0.9671666152648106,
          0.98468558802946,
          1.0178275181736574,
          0.980657443195294,
          1.0266368965939394,
          1.0387124690620373,
          1.025285100664745,
          1.1344366027859267,
          1.0832494231376286,
          1.0778240762422375,
          1.068379555417282,
          1.0445098208996275,
          1.0779056980467905,
          1.0931748145700046,
          1.12459294475006,
          1.115856106545024,
          1.1114649285805127,
          1.0968672799119472,
          1.10271900878617,
          1.129972884606169,
          1.1477913211905195,
          1.155602744537941,
          1.189742629754999,
          1.2110630442115171,
          1.1751993590303178,
          1.183927115646047,
          1.216279741365772,
          1.222820990588552,
          1.22441776261611,
          1.2265044859331442,
          1.213013658002661
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=AMZN<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "AMZN",
         "line": {
          "color": "#000002",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "AMZN",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.0618806117055757,
          1.0532404284307677,
          1.1406756202628388,
          1.1633743377885228,
          1.0898676795580526,
          1.1786207619316666,
          1.2203654438831366,
          1.2205688381237838,
          1.284548542665418,
          1.2786826844946546,
          1.2167532101702832,
          1.1775224533715958,
          1.1432627388670606,
          1.16405781403187,
          1.242730666448932,
          1.2794473988384474,
          1.2862244591394254,
          1.3040906767647622,
          1.2808711585229775,
          1.3099809658381354,
          1.3355191588974509,
          1.3700554610940725,
          1.3960736368996989,
          1.3958296232020404,
          1.3829181608736414,
          1.391729163581091,
          1.4750394640760272,
          1.4755844971819587,
          1.4784890230752108,
          1.4833867718479574,
          1.5346502643964448,
          1.5313308069300795,
          1.5501814209506477,
          1.637494456642517,
          1.5881591374274802,
          1.6029011479217037,
          1.5580080272628667,
          1.6295946560652816,
          1.5373757268816928,
          1.4551718788522234,
          1.435174192909178,
          1.3365524179114776,
          1.3550368620941855,
          1.3931936419790223,
          1.2963616956201691,
          1.22204146042711,
          1.375083410656027,
          1.3254226411301075,
          1.295141330176286,
          1.1206615472526131,
          1.202483038516975,
          1.2817010232963573,
          1.334721869745653,
          1.3799892040777797,
          1.359137222458745,
          1.3230632475991762,
          1.2921391799289847,
          1.3081910371293215,
          1.3273996770823542,
          1.3600809993969647,
          1.3186455808291295,
          1.393136635454831,
          1.435776232539301,
          1.4487771761299302,
          1.4947687054188046,
          1.4994712046698764,
          1.5146280474808236,
          1.5869876346023932,
          1.596612214272432,
          1.537644171481961,
          1.5205753430783882,
          1.483378627942562,
          1.44415601504927,
          1.4677172714127285,
          1.521120475440709,
          1.5549896884611636,
          1.540613747734834,
          1.58070684404494,
          1.6361032717659916,
          1.5982882308164057,
          1.5808207570233568,
          1.4833460531345568,
          1.4706054102388,
          1.4583936118945735,
          1.4234505212166575,
          1.445148654606286,
          1.491701504811883,
          1.4964446227063888,
          1.4596872708598625,
          1.4037863302335007,
          1.4153391824933792,
          1.4090502488441077,
          1.4298696556551374,
          1.43297747571907,
          1.4574742658589632,
          1.452950830015895,
          1.4152089825177483,
          1.420277551536714,
          1.465089434095106,
          1.425061388144621,
          1.4326601685000062,
          1.4534552436648156,
          1.52122624451373,
          1.503360026888393
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "candlestick": [
           {
            "decreasing": {
             "line": {
              "color": "#000033"
             }
            },
            "increasing": {
             "line": {
              "color": "#000032"
             }
            },
            "type": "candlestick"
           }
          ],
          "contour": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram2d": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "icicle": [
           {
            "textfont": {
             "color": "white"
            },
            "type": "icicle"
           }
          ],
          "sankey": [
           {
            "textfont": {
             "color": "#000036"
            },
            "type": "sankey"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "width": 0
             }
            },
            "type": "scatter"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#000038"
             },
             "font": {
              "color": "#000037"
             },
             "line": {
              "color": "#000039"
             }
            },
            "header": {
             "fill": {
              "color": "#000040"
             },
             "font": {
              "color": "#000036"
             },
             "line": {
              "color": "#000039"
             }
            },
            "type": "table"
           }
          ],
          "waterfall": [
           {
            "connector": {
             "line": {
              "color": "#000036",
              "width": 2
             }
            },
            "decreasing": {
             "marker": {
              "color": "#000033"
             }
            },
            "increasing": {
             "marker": {
              "color": "#000032"
             }
            },
            "totals": {
             "marker": {
              "color": "#000034"
             }
            },
            "type": "waterfall"
           }
          ]
         },
         "layout": {
          "coloraxis": {
           "colorscale": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#000021"
            ],
            [
             0.1,
             "#000022"
            ],
            [
             0.2,
             "#000023"
            ],
            [
             0.3,
             "#000024"
            ],
            [
             0.4,
             "#000025"
            ],
            [
             0.5,
             "#000026"
            ],
            [
             0.6,
             "#000027"
            ],
            [
             0.7,
             "#000028"
            ],
            [
             0.8,
             "#000029"
            ],
            [
             0.9,
             "#000030"
            ],
            [
             1,
             "#000031"
            ]
           ],
           "sequential": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorway": [
           "#000001",
           "#000002",
           "#000003",
           "#000004",
           "#000005",
           "#000006",
           "#000007",
           "#000008",
           "#000009",
           "#000010"
          ]
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mNone\u001b[0m\u001b[32;1m\u001b[1;3mI attempted to generate a line graph comparing Google and Amazon stocks using the stocks dataframe in Plotly Express, but it seems there was an issue, and I couldn't produce the graph. If there's anything else I can help you with or another way I can assist you, please let me know!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'can you use the stocks dataframe in plotly express to generate a line graph with comparing the Google and Amazon stocks?',\n",
       " 'output': \"I attempted to generate a line graph comparing Google and Amazon stocks using the stocks dataframe in Plotly Express, but it seems there was an issue, and I couldn't produce the graph. If there's anything else I can help you with or another way I can assist you, please let me know!\"}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"can you use the stocks dataframe in plotly express to generate a line graph with comparing the Google and Amazon stocks?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that it is using the correct Tool (which is great!), but not exactly returning a plot (which is what we want). Let's try to fix that by specifying the struture of our desired response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSure, I can help with that. Could you please specify which two stocks you would like to compare?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'can you use the stocks dataframe in plotly express to generate a line graph comparing two stocks?',\n",
       " 'output': 'Sure, I can help with that. Could you please specify which two stocks you would like to compare?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"can you use the stocks dataframe in plotly express to generate a line graph comparing two stocks?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIt seems like you're referring to something specific about Apple, but I need a bit more context to provide a helpful response. Could you please provide more details or clarify your request?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Apple is one of them',\n",
       " 'output': \"It seems like you're referring to something specific about Apple, but I need a bit more context to provide a helpful response. Could you please provide more details or clarify your request?\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor({\n",
    "    \"input\":\"Apple is one of them\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above the agent had no recollection of the prior conversation. Let's add **memory** to it. We'll **build the agent using *OpenAIToolsAgentOutputParser()*** and incorporate the **chat history**\n",
    "\n",
    "**Notice** how we manually bind the tools to the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We had this before: agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "# Now:\n",
    "tools = [px_trend_compare]\n",
    "llm_bound_tools = llm.bind_tools(tools)\n",
    "chat_history = [] \n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(x[\"intermediate_steps\"]), # Part of the prompt as well\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"] # Part of the prompt as well\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_bound_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's test its execution and check if it remembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSure, I can help with that. Could you please specify which two stocks you would like to compare?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input1 = \"can you use the stocks dataframe in plotly express to generate a line graph comparing two stocks?\"\n",
    "\n",
    "ai_interaction = agent_executor.invoke({\n",
    "    \"input\": input1,\n",
    "    \"chat_history\" : chat_history #Integrating chat_history\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'can you use the stocks dataframe in plotly express to generate a line graph comparing two stocks?',\n",
       " 'chat_history': [],\n",
       " 'output': 'Sure, I can help with that. Could you please specify which two stocks you would like to compare?'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure to extend chat history manually and add it to the agent invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mGreat choice! Could you please specify the second stock you'd like to compare with Apple?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content = ai_interaction[\"output\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "input2 = \"Apple is one of them\"\n",
    "\n",
    "ai_interaction = agent_executor.invoke({\n",
    "    \"input\": input2,\n",
    "    \"chat_history\" : chat_history #Extending with previous integrating chat_history\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Apple is one of them',\n",
       " 'chat_history': [HumanMessage(content='can you use the stocks dataframe in plotly express to generate a line graph comparing two stocks?'),\n",
       "  AIMessage(content='Sure, I can help with that. Could you please specify which two stocks you would like to compare?')],\n",
       " 'output': \"Great choice! Could you please specify the second stock you'd like to compare with Apple?\"}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory was added!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Agent Streaming\n",
    "\n",
    "Needed for App (e.g. StreamLit) interaction\n",
    "\n",
    "We need to add **with_config() tags** to the agent's llm and agentexecutor to be referenced in the ```astream_events``` API. Reference [here](https://python.langchain.com/docs/modules/agents/how_to/streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [px_trend_compare]\n",
    "llm_bound_tools = llm.bind_tools(tools)\n",
    "chat_history = [] \n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(x[\"intermediate_steps\"]), # Part of the prompt as well\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"] # Part of the prompt as well\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_bound_tools.with_config({\"tags\": [\"agent_llm\"]}) # THIS IS MODIFIED\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True).with_config({\"run_name\":\"Agent\"}) #THIS IS MODIFIED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The .astream method** outputs are action-observation pairs until an answer is achieved by the agent. The contents of the outputs are:\n",
    "- *Actions*: the actions the agent will take: agentaction() or messages() referring to the agent invocation\n",
    "- *Observations*: steps() with history of what agent has done so far and messages() with function invocation results.\n",
    "- *Final answer*: Agentfinish() output and messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "------\n",
      "{'actions': [...], 'messages': [...]}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `px_trend_compare` with `{'col1': 'AAPL', 'col2': 'AMZN', 'data': 'stocks'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=AAPL<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "AAPL",
         "line": {
          "color": "#000001",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "AAPL",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.0119428342857142,
          1.0197714685714288,
          0.9800571142857144,
          0.9171428571428571,
          0.8937714514285715,
          0.9853142457142856,
          1.002857142857143,
          1.006914325714286,
          1.02845712,
          1.0172571657142857,
          0.9425142971428572,
          0.9587428514285714,
          0.9621714571428572,
          0.99845712,
          0.9469714342857144,
          0.9275428971428572,
          1.0504571542857144,
          1.07765712,
          1.06462856,
          1.0776000114285715,
          1.0870857428571428,
          1.0954285542857145,
          1.0790856914285714,
          1.0566857028571428,
          1.0577714342857143,
          1.0741142914285715,
          1.093314297142857,
          1.0939428685714283,
          1.0913142628571428,
          1.1885143142857142,
          1.1858857085714285,
          1.2433142971428572,
          1.235200022857143,
          1.3007428857142855,
          1.2645714457142856,
          1.279085691428571,
          1.2437714514285716,
          1.2899428857142856,
          1.2816571028571428,
          1.2692000057142856,
          1.253199988571429,
          1.236000017142857,
          1.1855999771428571,
          1.1684000057142856,
          1.1058857085714286,
          0.9845142457142856,
          1.0204571542857144,
          0.9628000285714284,
          0.9455999771428572,
          0.8613142628571429,
          0.8927428342857143,
          0.8471999714285714,
          0.8702285314285714,
          0.8961143257142857,
          0.9014856857142858,
          0.95154288,
          0.9737714514285716,
          0.97382856,
          0.9884000057142855,
          0.9998285771428572,
          0.9880571657142858,
          1.0635428285714286,
          1.0917143028571428,
          1.0854285542857145,
          1.1257142857142857,
          1.1363999714285713,
          1.1649142914285715,
          1.1674285885714286,
          1.21,
          1.126742817142857,
          1.08,
          1.02268572,
          1.00040004,
          1.0865713942857145,
          1.1013714571428572,
          1.135885708571429,
          1.130971417142857,
          1.167028548571429,
          1.1617143028571428,
          1.15765712,
          1.1870857428571429,
          1.1658285942857145,
          1.1485143142857142,
          1.18,
          1.1579428514285717,
          1.1928000285714286,
          1.218628542857143,
          1.25,
          1.2441714057142856,
          1.25040004,
          1.2971999714285716,
          1.3497714685714286,
          1.3509143085714286,
          1.409028582857143,
          1.4618286114285712,
          1.4865143714285716,
          1.5186286285714288,
          1.4958857085714288,
          1.5271428571428571,
          1.5469142342857145,
          1.57228568,
          1.5968000114285714,
          1.6559999314285714,
          1.6779999657142857
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=AMZN<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "AMZN",
         "line": {
          "color": "#000002",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "AMZN",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.0618806117055757,
          1.0532404284307677,
          1.1406756202628388,
          1.1633743377885228,
          1.0898676795580526,
          1.1786207619316666,
          1.2203654438831366,
          1.2205688381237838,
          1.284548542665418,
          1.2786826844946546,
          1.2167532101702832,
          1.1775224533715958,
          1.1432627388670606,
          1.16405781403187,
          1.242730666448932,
          1.2794473988384474,
          1.2862244591394254,
          1.3040906767647622,
          1.2808711585229775,
          1.3099809658381354,
          1.3355191588974509,
          1.3700554610940725,
          1.3960736368996989,
          1.3958296232020404,
          1.3829181608736414,
          1.391729163581091,
          1.4750394640760272,
          1.4755844971819587,
          1.4784890230752108,
          1.4833867718479574,
          1.5346502643964448,
          1.5313308069300795,
          1.5501814209506477,
          1.637494456642517,
          1.5881591374274802,
          1.6029011479217037,
          1.5580080272628667,
          1.6295946560652816,
          1.5373757268816928,
          1.4551718788522234,
          1.435174192909178,
          1.3365524179114776,
          1.3550368620941855,
          1.3931936419790223,
          1.2963616956201691,
          1.22204146042711,
          1.375083410656027,
          1.3254226411301075,
          1.295141330176286,
          1.1206615472526131,
          1.202483038516975,
          1.2817010232963573,
          1.334721869745653,
          1.3799892040777797,
          1.359137222458745,
          1.3230632475991762,
          1.2921391799289847,
          1.3081910371293215,
          1.3273996770823542,
          1.3600809993969647,
          1.3186455808291295,
          1.393136635454831,
          1.435776232539301,
          1.4487771761299302,
          1.4947687054188046,
          1.4994712046698764,
          1.5146280474808236,
          1.5869876346023932,
          1.596612214272432,
          1.537644171481961,
          1.5205753430783882,
          1.483378627942562,
          1.44415601504927,
          1.4677172714127285,
          1.521120475440709,
          1.5549896884611636,
          1.540613747734834,
          1.58070684404494,
          1.6361032717659916,
          1.5982882308164057,
          1.5808207570233568,
          1.4833460531345568,
          1.4706054102388,
          1.4583936118945735,
          1.4234505212166575,
          1.445148654606286,
          1.491701504811883,
          1.4964446227063888,
          1.4596872708598625,
          1.4037863302335007,
          1.4153391824933792,
          1.4090502488441077,
          1.4298696556551374,
          1.43297747571907,
          1.4574742658589632,
          1.452950830015895,
          1.4152089825177483,
          1.420277551536714,
          1.465089434095106,
          1.425061388144621,
          1.4326601685000062,
          1.4534552436648156,
          1.52122624451373,
          1.503360026888393
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "candlestick": [
           {
            "decreasing": {
             "line": {
              "color": "#000033"
             }
            },
            "increasing": {
             "line": {
              "color": "#000032"
             }
            },
            "type": "candlestick"
           }
          ],
          "contour": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram2d": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "icicle": [
           {
            "textfont": {
             "color": "white"
            },
            "type": "icicle"
           }
          ],
          "sankey": [
           {
            "textfont": {
             "color": "#000036"
            },
            "type": "sankey"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "width": 0
             }
            },
            "type": "scatter"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#000038"
             },
             "font": {
              "color": "#000037"
             },
             "line": {
              "color": "#000039"
             }
            },
            "header": {
             "fill": {
              "color": "#000040"
             },
             "font": {
              "color": "#000036"
             },
             "line": {
              "color": "#000039"
             }
            },
            "type": "table"
           }
          ],
          "waterfall": [
           {
            "connector": {
             "line": {
              "color": "#000036",
              "width": 2
             }
            },
            "decreasing": {
             "marker": {
              "color": "#000033"
             }
            },
            "increasing": {
             "marker": {
              "color": "#000032"
             }
            },
            "totals": {
             "marker": {
              "color": "#000034"
             }
            },
            "type": "waterfall"
           }
          ]
         },
         "layout": {
          "coloraxis": {
           "colorscale": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#000021"
            ],
            [
             0.1,
             "#000022"
            ],
            [
             0.2,
             "#000023"
            ],
            [
             0.3,
             "#000024"
            ],
            [
             0.4,
             "#000025"
            ],
            [
             0.5,
             "#000026"
            ],
            [
             0.6,
             "#000027"
            ],
            [
             0.7,
             "#000028"
            ],
            [
             0.8,
             "#000029"
            ],
            [
             0.9,
             "#000030"
            ],
            [
             1,
             "#000031"
            ]
           ],
           "sequential": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorway": [
           "#000001",
           "#000002",
           "#000003",
           "#000004",
           "#000005",
           "#000006",
           "#000007",
           "#000008",
           "#000009",
           "#000010"
          ]
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mNone\u001b[0m------\n",
      "{'messages': [...], 'steps': [...]}\n",
      "\u001b[32;1m\u001b[1;3mI attempted to generate a line graph comparing Amazon and Apple using the stocks data from Plotly Express, but it seems there was an issue with the process. Unfortunately, I'm unable to provide the graph at this moment. Is there anything else I can assist you with?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "------\n",
      "{'messages': [...],\n",
      " 'output': 'I attempted to generate a line graph comparing Amazon and Apple '\n",
      "           'using the stocks data from Plotly Express, but it seems there was '\n",
      "           \"an issue with the process. Unfortunately, I'm unable to provide \"\n",
      "           'the graph at this moment. Is there anything else I can assist you '\n",
      "           'with?'}\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "input1 = \"can you use the stocks dataframe in plotly express to generate a line graph comparing amazon and apple?\"\n",
    "\n",
    "async for chunk in agent_executor.astream({\n",
    "# for chunk in agent_executor.stream({\n",
    "    \"input\": input1,\n",
    "    \"chat_history\" : chat_history #Integrating chat_history\n",
    "}):\n",
    "    chunks.append(chunk)\n",
    "    print(\"------\")\n",
    "    pprint.pprint(chunk, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the actions, observations and final outputs in the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'actions': [OpenAIToolAgentAction(tool='px_trend_compare', tool_input={'col1': 'AAPL', 'col2': 'AMZN', 'data': 'stocks'}, log=\"\\nInvoking: `px_trend_compare` with `{'col1': 'AAPL', 'col2': 'AMZN', 'data': 'stocks'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_61YIQWaUQDeu5vuAolFQ2hzu', 'function': {'arguments': '{\"col1\":\"AAPL\",\"col2\":\"AMZN\",\"data\":\"stocks\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})], tool_call_id='call_61YIQWaUQDeu5vuAolFQ2hzu')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_61YIQWaUQDeu5vuAolFQ2hzu', 'function': {'arguments': '{\"col1\":\"AAPL\",\"col2\":\"AMZN\",\"data\":\"stocks\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})]},\n",
       " {'steps': [AgentStep(action=OpenAIToolAgentAction(tool='px_trend_compare', tool_input={'col1': 'AAPL', 'col2': 'AMZN', 'data': 'stocks'}, log=\"\\nInvoking: `px_trend_compare` with `{'col1': 'AAPL', 'col2': 'AMZN', 'data': 'stocks'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_61YIQWaUQDeu5vuAolFQ2hzu', 'function': {'arguments': '{\"col1\":\"AAPL\",\"col2\":\"AMZN\",\"data\":\"stocks\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})], tool_call_id='call_61YIQWaUQDeu5vuAolFQ2hzu'))],\n",
       "  'messages': [FunctionMessage(content='null', name='px_trend_compare')]},\n",
       " {'output': \"I attempted to generate a line graph comparing Amazon and Apple using the stocks data from Plotly Express, but it seems there was an issue with the process. Unfortunately, I'm unable to provide the graph at this moment. Is there anything else I can assist you with?\",\n",
       "  'messages': [AIMessage(content=\"I attempted to generate a line graph comparing Amazon and Apple using the stocks data from Plotly Express, but it seems there was an issue with the process. Unfortunately, I'm unable to provide the graph at this moment. Is there anything else I can assist you with?\")]}]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_61YIQWaUQDeu5vuAolFQ2hzu', 'function': {'arguments': '{\"col1\":\"AAPL\",\"col2\":\"AMZN\",\"data\":\"stocks\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})]\n",
      "[FunctionMessage(content='null', name='px_trend_compare')]\n",
      "[AIMessage(content=\"I attempted to generate a line graph comparing Amazon and Apple using the stocks data from Plotly Express, but it seems there was an issue with the process. Unfortunately, I'm unable to provide the graph at this moment. Is there anything else I can assist you with?\")]\n"
     ]
    }
   ],
   "source": [
    "for i in chunks:\n",
    "    print(i[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can format the output (during streaming) to give us an idea of how to display it in our app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling Tool: `px_trend_compare` with input `{'col1': 'AAPL', 'col2': 'AMZN', 'data': 'stocks'}`\n",
      "---\n",
      "action=OpenAIToolAgentAction(tool='px_trend_compare', tool_input={'col1': 'AAPL', 'col2': 'AMZN', 'data': 'stocks'}, log=\"\\nInvoking: `px_trend_compare` with `{'col1': 'AAPL', 'col2': 'AMZN', 'data': 'stocks'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BFkyWbb9vvpUFCXoiRmUzDuS', 'function': {'arguments': '{\"col1\":\"AAPL\",\"col2\":\"AMZN\",\"data\":\"stocks\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})], tool_call_id='call_BFkyWbb9vvpUFCXoiRmUzDuS') \n",
      "\n",
      "Tool Result: `None`\n",
      "---\n",
      "Final Output: I attempted to generate a line graph comparing Amazon and Apple using the stocks dataframe in Plotly Express, but it seems there was an issue with the process. Unfortunately, I'm unable to display the graph at this moment. Is there anything else I can assist you with?\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    # Agent Action\n",
    "    if \"actions\" in chunk:\n",
    "        for action in chunk[\"actions\"]:\n",
    "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
    "    # Observation\n",
    "    elif \"steps\" in chunk:\n",
    "        for step in chunk[\"steps\"]:\n",
    "            print(step, \"\\n\")\n",
    "            print(f\"Tool Result: `{step.observation}`\")\n",
    "    # Final result\n",
    "    elif \"output\" in chunk:\n",
    "        print(f'Final Output: {chunk[\"output\"]}')\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_stream_response = agent_executor.stream({\n",
    "    \"input\": input1,\n",
    "    \"chat_history\" : chat_history #Integrating chat_history\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object RunnableBindingBase.stream at 0x157291ba0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_stream_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 00:30:17.891 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `px_trend_compare` with `{'col1': 'AMZN', 'col2': 'AAPL', 'data': 'stocks'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=AMZN<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "AMZN",
         "line": {
          "color": "#000001",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "AMZN",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.0618806117055757,
          1.0532404284307677,
          1.1406756202628388,
          1.1633743377885228,
          1.0898676795580526,
          1.1786207619316666,
          1.2203654438831366,
          1.2205688381237838,
          1.284548542665418,
          1.2786826844946546,
          1.2167532101702832,
          1.1775224533715958,
          1.1432627388670606,
          1.16405781403187,
          1.242730666448932,
          1.2794473988384474,
          1.2862244591394254,
          1.3040906767647622,
          1.2808711585229775,
          1.3099809658381354,
          1.3355191588974509,
          1.3700554610940725,
          1.3960736368996989,
          1.3958296232020404,
          1.3829181608736414,
          1.391729163581091,
          1.4750394640760272,
          1.4755844971819587,
          1.4784890230752108,
          1.4833867718479574,
          1.5346502643964448,
          1.5313308069300795,
          1.5501814209506477,
          1.637494456642517,
          1.5881591374274802,
          1.6029011479217037,
          1.5580080272628667,
          1.6295946560652816,
          1.5373757268816928,
          1.4551718788522234,
          1.435174192909178,
          1.3365524179114776,
          1.3550368620941855,
          1.3931936419790223,
          1.2963616956201691,
          1.22204146042711,
          1.375083410656027,
          1.3254226411301075,
          1.295141330176286,
          1.1206615472526131,
          1.202483038516975,
          1.2817010232963573,
          1.334721869745653,
          1.3799892040777797,
          1.359137222458745,
          1.3230632475991762,
          1.2921391799289847,
          1.3081910371293215,
          1.3273996770823542,
          1.3600809993969647,
          1.3186455808291295,
          1.393136635454831,
          1.435776232539301,
          1.4487771761299302,
          1.4947687054188046,
          1.4994712046698764,
          1.5146280474808236,
          1.5869876346023932,
          1.596612214272432,
          1.537644171481961,
          1.5205753430783882,
          1.483378627942562,
          1.44415601504927,
          1.4677172714127285,
          1.521120475440709,
          1.5549896884611636,
          1.540613747734834,
          1.58070684404494,
          1.6361032717659916,
          1.5982882308164057,
          1.5808207570233568,
          1.4833460531345568,
          1.4706054102388,
          1.4583936118945735,
          1.4234505212166575,
          1.445148654606286,
          1.491701504811883,
          1.4964446227063888,
          1.4596872708598625,
          1.4037863302335007,
          1.4153391824933792,
          1.4090502488441077,
          1.4298696556551374,
          1.43297747571907,
          1.4574742658589632,
          1.452950830015895,
          1.4152089825177483,
          1.420277551536714,
          1.465089434095106,
          1.425061388144621,
          1.4326601685000062,
          1.4534552436648156,
          1.52122624451373,
          1.503360026888393
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=AAPL<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "AAPL",
         "line": {
          "color": "#000002",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "AAPL",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.0119428342857142,
          1.0197714685714288,
          0.9800571142857144,
          0.9171428571428571,
          0.8937714514285715,
          0.9853142457142856,
          1.002857142857143,
          1.006914325714286,
          1.02845712,
          1.0172571657142857,
          0.9425142971428572,
          0.9587428514285714,
          0.9621714571428572,
          0.99845712,
          0.9469714342857144,
          0.9275428971428572,
          1.0504571542857144,
          1.07765712,
          1.06462856,
          1.0776000114285715,
          1.0870857428571428,
          1.0954285542857145,
          1.0790856914285714,
          1.0566857028571428,
          1.0577714342857143,
          1.0741142914285715,
          1.093314297142857,
          1.0939428685714283,
          1.0913142628571428,
          1.1885143142857142,
          1.1858857085714285,
          1.2433142971428572,
          1.235200022857143,
          1.3007428857142855,
          1.2645714457142856,
          1.279085691428571,
          1.2437714514285716,
          1.2899428857142856,
          1.2816571028571428,
          1.2692000057142856,
          1.253199988571429,
          1.236000017142857,
          1.1855999771428571,
          1.1684000057142856,
          1.1058857085714286,
          0.9845142457142856,
          1.0204571542857144,
          0.9628000285714284,
          0.9455999771428572,
          0.8613142628571429,
          0.8927428342857143,
          0.8471999714285714,
          0.8702285314285714,
          0.8961143257142857,
          0.9014856857142858,
          0.95154288,
          0.9737714514285716,
          0.97382856,
          0.9884000057142855,
          0.9998285771428572,
          0.9880571657142858,
          1.0635428285714286,
          1.0917143028571428,
          1.0854285542857145,
          1.1257142857142857,
          1.1363999714285713,
          1.1649142914285715,
          1.1674285885714286,
          1.21,
          1.126742817142857,
          1.08,
          1.02268572,
          1.00040004,
          1.0865713942857145,
          1.1013714571428572,
          1.135885708571429,
          1.130971417142857,
          1.167028548571429,
          1.1617143028571428,
          1.15765712,
          1.1870857428571429,
          1.1658285942857145,
          1.1485143142857142,
          1.18,
          1.1579428514285717,
          1.1928000285714286,
          1.218628542857143,
          1.25,
          1.2441714057142856,
          1.25040004,
          1.2971999714285716,
          1.3497714685714286,
          1.3509143085714286,
          1.409028582857143,
          1.4618286114285712,
          1.4865143714285716,
          1.5186286285714288,
          1.4958857085714288,
          1.5271428571428571,
          1.5469142342857145,
          1.57228568,
          1.5968000114285714,
          1.6559999314285714,
          1.6779999657142857
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "candlestick": [
           {
            "decreasing": {
             "line": {
              "color": "#000033"
             }
            },
            "increasing": {
             "line": {
              "color": "#000032"
             }
            },
            "type": "candlestick"
           }
          ],
          "contour": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram2d": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "icicle": [
           {
            "textfont": {
             "color": "white"
            },
            "type": "icicle"
           }
          ],
          "sankey": [
           {
            "textfont": {
             "color": "#000036"
            },
            "type": "sankey"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "width": 0
             }
            },
            "type": "scatter"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#000038"
             },
             "font": {
              "color": "#000037"
             },
             "line": {
              "color": "#000039"
             }
            },
            "header": {
             "fill": {
              "color": "#000040"
             },
             "font": {
              "color": "#000036"
             },
             "line": {
              "color": "#000039"
             }
            },
            "type": "table"
           }
          ],
          "waterfall": [
           {
            "connector": {
             "line": {
              "color": "#000036",
              "width": 2
             }
            },
            "decreasing": {
             "marker": {
              "color": "#000033"
             }
            },
            "increasing": {
             "marker": {
              "color": "#000032"
             }
            },
            "totals": {
             "marker": {
              "color": "#000034"
             }
            },
            "type": "waterfall"
           }
          ]
         },
         "layout": {
          "coloraxis": {
           "colorscale": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#000021"
            ],
            [
             0.1,
             "#000022"
            ],
            [
             0.2,
             "#000023"
            ],
            [
             0.3,
             "#000024"
            ],
            [
             0.4,
             "#000025"
            ],
            [
             0.5,
             "#000026"
            ],
            [
             0.6,
             "#000027"
            ],
            [
             0.7,
             "#000028"
            ],
            [
             0.8,
             "#000029"
            ],
            [
             0.9,
             "#000030"
            ],
            [
             1,
             "#000031"
            ]
           ],
           "sequential": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorway": [
           "#000001",
           "#000002",
           "#000003",
           "#000004",
           "#000005",
           "#000006",
           "#000007",
           "#000008",
           "#000009",
           "#000010"
          ]
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mNone\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `px_trend_compare` with `{'data': 'stocks', 'col1': 'AMZN', 'col2': 'AAPL'}`\n",
      "responded: I've generated the comparison, but it seems there was an issue displaying the graph. Let me try again to ensure you get the visual comparison between Amazon (AMZN) and Apple (AAPL) stock prices.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=AMZN<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "AMZN",
         "line": {
          "color": "#000001",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "AMZN",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.0618806117055757,
          1.0532404284307677,
          1.1406756202628388,
          1.1633743377885228,
          1.0898676795580526,
          1.1786207619316666,
          1.2203654438831366,
          1.2205688381237838,
          1.284548542665418,
          1.2786826844946546,
          1.2167532101702832,
          1.1775224533715958,
          1.1432627388670606,
          1.16405781403187,
          1.242730666448932,
          1.2794473988384474,
          1.2862244591394254,
          1.3040906767647622,
          1.2808711585229775,
          1.3099809658381354,
          1.3355191588974509,
          1.3700554610940725,
          1.3960736368996989,
          1.3958296232020404,
          1.3829181608736414,
          1.391729163581091,
          1.4750394640760272,
          1.4755844971819587,
          1.4784890230752108,
          1.4833867718479574,
          1.5346502643964448,
          1.5313308069300795,
          1.5501814209506477,
          1.637494456642517,
          1.5881591374274802,
          1.6029011479217037,
          1.5580080272628667,
          1.6295946560652816,
          1.5373757268816928,
          1.4551718788522234,
          1.435174192909178,
          1.3365524179114776,
          1.3550368620941855,
          1.3931936419790223,
          1.2963616956201691,
          1.22204146042711,
          1.375083410656027,
          1.3254226411301075,
          1.295141330176286,
          1.1206615472526131,
          1.202483038516975,
          1.2817010232963573,
          1.334721869745653,
          1.3799892040777797,
          1.359137222458745,
          1.3230632475991762,
          1.2921391799289847,
          1.3081910371293215,
          1.3273996770823542,
          1.3600809993969647,
          1.3186455808291295,
          1.393136635454831,
          1.435776232539301,
          1.4487771761299302,
          1.4947687054188046,
          1.4994712046698764,
          1.5146280474808236,
          1.5869876346023932,
          1.596612214272432,
          1.537644171481961,
          1.5205753430783882,
          1.483378627942562,
          1.44415601504927,
          1.4677172714127285,
          1.521120475440709,
          1.5549896884611636,
          1.540613747734834,
          1.58070684404494,
          1.6361032717659916,
          1.5982882308164057,
          1.5808207570233568,
          1.4833460531345568,
          1.4706054102388,
          1.4583936118945735,
          1.4234505212166575,
          1.445148654606286,
          1.491701504811883,
          1.4964446227063888,
          1.4596872708598625,
          1.4037863302335007,
          1.4153391824933792,
          1.4090502488441077,
          1.4298696556551374,
          1.43297747571907,
          1.4574742658589632,
          1.452950830015895,
          1.4152089825177483,
          1.420277551536714,
          1.465089434095106,
          1.425061388144621,
          1.4326601685000062,
          1.4534552436648156,
          1.52122624451373,
          1.503360026888393
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=AAPL<br>date=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "AAPL",
         "line": {
          "color": "#000002",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "AAPL",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-01-01",
          "2018-01-08",
          "2018-01-15",
          "2018-01-22",
          "2018-01-29",
          "2018-02-05",
          "2018-02-12",
          "2018-02-19",
          "2018-02-26",
          "2018-03-05",
          "2018-03-12",
          "2018-03-19",
          "2018-03-26",
          "2018-04-02",
          "2018-04-09",
          "2018-04-16",
          "2018-04-23",
          "2018-04-30",
          "2018-05-07",
          "2018-05-14",
          "2018-05-21",
          "2018-05-28",
          "2018-06-04",
          "2018-06-11",
          "2018-06-18",
          "2018-06-25",
          "2018-07-02",
          "2018-07-09",
          "2018-07-16",
          "2018-07-23",
          "2018-07-30",
          "2018-08-06",
          "2018-08-13",
          "2018-08-20",
          "2018-08-27",
          "2018-09-03",
          "2018-09-10",
          "2018-09-17",
          "2018-09-24",
          "2018-10-01",
          "2018-10-08",
          "2018-10-15",
          "2018-10-22",
          "2018-10-29",
          "2018-11-05",
          "2018-11-12",
          "2018-11-19",
          "2018-11-26",
          "2018-12-03",
          "2018-12-10",
          "2018-12-17",
          "2018-12-24",
          "2018-12-31",
          "2019-01-07",
          "2019-01-14",
          "2019-01-21",
          "2019-01-28",
          "2019-02-04",
          "2019-02-11",
          "2019-02-18",
          "2019-02-25",
          "2019-03-04",
          "2019-03-11",
          "2019-03-18",
          "2019-03-25",
          "2019-04-01",
          "2019-04-08",
          "2019-04-15",
          "2019-04-22",
          "2019-04-29",
          "2019-05-06",
          "2019-05-13",
          "2019-05-20",
          "2019-05-27",
          "2019-06-03",
          "2019-06-10",
          "2019-06-17",
          "2019-06-24",
          "2019-07-01",
          "2019-07-08",
          "2019-07-15",
          "2019-07-22",
          "2019-07-29",
          "2019-08-05",
          "2019-08-12",
          "2019-08-19",
          "2019-08-26",
          "2019-09-02",
          "2019-09-09",
          "2019-09-16",
          "2019-09-23",
          "2019-09-30",
          "2019-10-07",
          "2019-10-14",
          "2019-10-21",
          "2019-10-28",
          "2019-11-04",
          "2019-11-11",
          "2019-11-18",
          "2019-11-25",
          "2019-12-02",
          "2019-12-09",
          "2019-12-16",
          "2019-12-23",
          "2019-12-30"
         ],
         "xaxis": "x",
         "y": [
          1,
          1.0119428342857142,
          1.0197714685714288,
          0.9800571142857144,
          0.9171428571428571,
          0.8937714514285715,
          0.9853142457142856,
          1.002857142857143,
          1.006914325714286,
          1.02845712,
          1.0172571657142857,
          0.9425142971428572,
          0.9587428514285714,
          0.9621714571428572,
          0.99845712,
          0.9469714342857144,
          0.9275428971428572,
          1.0504571542857144,
          1.07765712,
          1.06462856,
          1.0776000114285715,
          1.0870857428571428,
          1.0954285542857145,
          1.0790856914285714,
          1.0566857028571428,
          1.0577714342857143,
          1.0741142914285715,
          1.093314297142857,
          1.0939428685714283,
          1.0913142628571428,
          1.1885143142857142,
          1.1858857085714285,
          1.2433142971428572,
          1.235200022857143,
          1.3007428857142855,
          1.2645714457142856,
          1.279085691428571,
          1.2437714514285716,
          1.2899428857142856,
          1.2816571028571428,
          1.2692000057142856,
          1.253199988571429,
          1.236000017142857,
          1.1855999771428571,
          1.1684000057142856,
          1.1058857085714286,
          0.9845142457142856,
          1.0204571542857144,
          0.9628000285714284,
          0.9455999771428572,
          0.8613142628571429,
          0.8927428342857143,
          0.8471999714285714,
          0.8702285314285714,
          0.8961143257142857,
          0.9014856857142858,
          0.95154288,
          0.9737714514285716,
          0.97382856,
          0.9884000057142855,
          0.9998285771428572,
          0.9880571657142858,
          1.0635428285714286,
          1.0917143028571428,
          1.0854285542857145,
          1.1257142857142857,
          1.1363999714285713,
          1.1649142914285715,
          1.1674285885714286,
          1.21,
          1.126742817142857,
          1.08,
          1.02268572,
          1.00040004,
          1.0865713942857145,
          1.1013714571428572,
          1.135885708571429,
          1.130971417142857,
          1.167028548571429,
          1.1617143028571428,
          1.15765712,
          1.1870857428571429,
          1.1658285942857145,
          1.1485143142857142,
          1.18,
          1.1579428514285717,
          1.1928000285714286,
          1.218628542857143,
          1.25,
          1.2441714057142856,
          1.25040004,
          1.2971999714285716,
          1.3497714685714286,
          1.3509143085714286,
          1.409028582857143,
          1.4618286114285712,
          1.4865143714285716,
          1.5186286285714288,
          1.4958857085714288,
          1.5271428571428571,
          1.5469142342857145,
          1.57228568,
          1.5968000114285714,
          1.6559999314285714,
          1.6779999657142857
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "candlestick": [
           {
            "decreasing": {
             "line": {
              "color": "#000033"
             }
            },
            "increasing": {
             "line": {
              "color": "#000032"
             }
            },
            "type": "candlestick"
           }
          ],
          "contour": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram2d": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "icicle": [
           {
            "textfont": {
             "color": "white"
            },
            "type": "icicle"
           }
          ],
          "sankey": [
           {
            "textfont": {
             "color": "#000036"
            },
            "type": "sankey"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "width": 0
             }
            },
            "type": "scatter"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#000038"
             },
             "font": {
              "color": "#000037"
             },
             "line": {
              "color": "#000039"
             }
            },
            "header": {
             "fill": {
              "color": "#000040"
             },
             "font": {
              "color": "#000036"
             },
             "line": {
              "color": "#000039"
             }
            },
            "type": "table"
           }
          ],
          "waterfall": [
           {
            "connector": {
             "line": {
              "color": "#000036",
              "width": 2
             }
            },
            "decreasing": {
             "marker": {
              "color": "#000033"
             }
            },
            "increasing": {
             "marker": {
              "color": "#000032"
             }
            },
            "totals": {
             "marker": {
              "color": "#000034"
             }
            },
            "type": "waterfall"
           }
          ]
         },
         "layout": {
          "coloraxis": {
           "colorscale": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#000021"
            ],
            [
             0.1,
             "#000022"
            ],
            [
             0.2,
             "#000023"
            ],
            [
             0.3,
             "#000024"
            ],
            [
             0.4,
             "#000025"
            ],
            [
             0.5,
             "#000026"
            ],
            [
             0.6,
             "#000027"
            ],
            [
             0.7,
             "#000028"
            ],
            [
             0.8,
             "#000029"
            ],
            [
             0.9,
             "#000030"
            ],
            [
             1,
             "#000031"
            ]
           ],
           "sequential": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorway": [
           "#000001",
           "#000002",
           "#000003",
           "#000004",
           "#000005",
           "#000006",
           "#000007",
           "#000008",
           "#000009",
           "#000010"
          ]
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mNone\u001b[0m\u001b[32;1m\u001b[1;3mIt appears there's a persistent issue preventing the display of the line graph comparing Amazon (AMZN) and Apple (AAPL) stock prices. Unfortunately, I'm unable to provide the visual comparison at this moment. If you have any other requests or need assistance with a different query, please let me know!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [OpenAIToolAgentAction(tool='px_trend_compare', tool_input={'col1': 'AMZN', 'col2': 'AAPL', 'data': 'stocks'}, log=\"\\nInvoking: `px_trend_compare` with `{'col1': 'AMZN', 'col2': 'AAPL', 'data': 'stocks'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_jmkCDayV5A5JNtGbABBZdQjL', 'function': {'arguments': '{\"col1\":\"AMZN\",\"col2\":\"AAPL\",\"data\":\"stocks\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})], tool_call_id='call_jmkCDayV5A5JNtGbABBZdQjL')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_jmkCDayV5A5JNtGbABBZdQjL', 'function': {'arguments': '{\"col1\":\"AMZN\",\"col2\":\"AAPL\",\"data\":\"stocks\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})]},\n",
       " {'steps': [AgentStep(action=OpenAIToolAgentAction(tool='px_trend_compare', tool_input={'col1': 'AMZN', 'col2': 'AAPL', 'data': 'stocks'}, log=\"\\nInvoking: `px_trend_compare` with `{'col1': 'AMZN', 'col2': 'AAPL', 'data': 'stocks'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_jmkCDayV5A5JNtGbABBZdQjL', 'function': {'arguments': '{\"col1\":\"AMZN\",\"col2\":\"AAPL\",\"data\":\"stocks\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})], tool_call_id='call_jmkCDayV5A5JNtGbABBZdQjL'))],\n",
       "  'messages': [FunctionMessage(content='null', name='px_trend_compare')]},\n",
       " {'actions': [OpenAIToolAgentAction(tool='px_trend_compare', tool_input={'data': 'stocks', 'col1': 'AMZN', 'col2': 'AAPL'}, log=\"\\nInvoking: `px_trend_compare` with `{'data': 'stocks', 'col1': 'AMZN', 'col2': 'AAPL'}`\\nresponded: I've generated the comparison, but it seems there was an issue displaying the graph. Let me try again to ensure you get the visual comparison between Amazon (AMZN) and Apple (AAPL) stock prices.\\n\\n\", message_log=[AIMessageChunk(content=\"I've generated the comparison, but it seems there was an issue displaying the graph. Let me try again to ensure you get the visual comparison between Amazon (AMZN) and Apple (AAPL) stock prices.\", additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_ZE37s27VHOFdtd9kK6sxAgPW', 'function': {'arguments': '{\"data\":\"stocks\",\"col1\":\"AMZN\",\"col2\":\"AAPL\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})], tool_call_id='call_ZE37s27VHOFdtd9kK6sxAgPW')],\n",
       "  'messages': [AIMessageChunk(content=\"I've generated the comparison, but it seems there was an issue displaying the graph. Let me try again to ensure you get the visual comparison between Amazon (AMZN) and Apple (AAPL) stock prices.\", additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_ZE37s27VHOFdtd9kK6sxAgPW', 'function': {'arguments': '{\"data\":\"stocks\",\"col1\":\"AMZN\",\"col2\":\"AAPL\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})]},\n",
       " {'steps': [AgentStep(action=OpenAIToolAgentAction(tool='px_trend_compare', tool_input={'data': 'stocks', 'col1': 'AMZN', 'col2': 'AAPL'}, log=\"\\nInvoking: `px_trend_compare` with `{'data': 'stocks', 'col1': 'AMZN', 'col2': 'AAPL'}`\\nresponded: I've generated the comparison, but it seems there was an issue displaying the graph. Let me try again to ensure you get the visual comparison between Amazon (AMZN) and Apple (AAPL) stock prices.\\n\\n\", message_log=[AIMessageChunk(content=\"I've generated the comparison, but it seems there was an issue displaying the graph. Let me try again to ensure you get the visual comparison between Amazon (AMZN) and Apple (AAPL) stock prices.\", additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_ZE37s27VHOFdtd9kK6sxAgPW', 'function': {'arguments': '{\"data\":\"stocks\",\"col1\":\"AMZN\",\"col2\":\"AAPL\"}', 'name': 'px_trend_compare'}, 'type': 'function'}]})], tool_call_id='call_ZE37s27VHOFdtd9kK6sxAgPW'))],\n",
       "  'messages': [FunctionMessage(content='null', name='px_trend_compare')]},\n",
       " {'output': \"It appears there's a persistent issue preventing the display of the line graph comparing Amazon (AMZN) and Apple (AAPL) stock prices. Unfortunately, I'm unable to provide the visual comparison at this moment. If you have any other requests or need assistance with a different query, please let me know!\",\n",
       "  'messages': [AIMessage(content=\"It appears there's a persistent issue preventing the display of the line graph comparing Amazon (AMZN) and Apple (AAPL) stock prices. Unfortunately, I'm unable to provide the visual comparison at this moment. If you have any other requests or need assistance with a different query, please let me know!\")]}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.write_stream(agent_stream_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate additional prompt types suitable for Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenAI Tool Agent Prompt**. Has *messages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tools'], template='\\nYou are a helpful assistant. Assistant has access to the following tools: {tools}\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [one of the tools provided]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate, PromptTemplate\n",
    "\n",
    "\n",
    "system_prompt =\"\"\"\n",
    "You are a helpful assistant. Assistant has access to the following tools: {tools}\n",
    "\n",
    "To use a tool, please use the following format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [one of the tools provided]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "```\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? No\n",
    "Final Answer: [your response here]\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt.messages[0] = (\n",
    "    SystemMessagePromptTemplate(prompt = PromptTemplate(input_variables=[\"tools\"],\n",
    "                                                        template=system_prompt))\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tools'], template='\\nYou are a helpful assistant. Assistant has access to the following tools: {tools}\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [one of the tools provided]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "You are a helpful assistant. Assistant has access to the following tools: \u001b[33;1m\u001b[1;3m{tools}\u001b[0m\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [one of the tools provided]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "Final Answer: [your response here]\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reach Prompt**. No messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PromptTemplate' object has no attribute 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m react_prompt \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mpull(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhwchase17/react\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mreact_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PromptTemplate' object has no attribute 'messages'"
     ]
    }
   ],
   "source": [
    "react_prompt = hub.pull(\"hwchase17/react\")\n",
    "react_prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{tools}\u001b[0m\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [\u001b[33;1m\u001b[1;3m{tool_names}\u001b[0m]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "Thought:\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "react_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**React + Chat**. No *messages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'], template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n{tools}\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_chat_prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "react_chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PromptTemplate' object has no attribute 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreact_chat_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PromptTemplate' object has no attribute 'messages'"
     ]
    }
   ],
   "source": [
    "react_chat_prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{tools}\u001b[0m\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [\u001b[33;1m\u001b[1;3m{tool_names}\u001b[0m]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "Final Answer: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "New input: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "react_chat_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test these with a dummy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def where_cat_is_hiding() -> str:\n",
    "    \"\"\"Where is the cat hiding right now?\"\"\"\n",
    "    return random.choice([\"under the bed\", \"on the shelf\"])\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_items(place: str) -> str:\n",
    "    \"\"\"Use this tool to look up which items are in the given place.\"\"\"\n",
    "    if \"bed\" in place:  # For under the bed\n",
    "        return \"socks, shoes and dust bunnies\"\n",
    "    if \"shelf\" in place:  # For 'shelf'\n",
    "        return \"books, penciles and pictures\"\n",
    "    else:  # if the agent decides to ask about a different place\n",
    "        return \"cat snacks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Testing OpenAI Tool Agent Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [where_cat_is_hiding, get_items]\n",
    "llm_bound_tools = llm.bind_tools(tools)\n",
    "chat_history = [] \n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(x[\"intermediate_steps\"]), # Part of the prompt as well\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"], # Part of the prompt as well,\n",
    "        \"tools\": lambda x: \" and \".join([i.get_name() for i in x[\"tools\"]]) \n",
    "    }\n",
    "    | prompt\n",
    "    | llm_bound_tools.with_config({\"tags\": [\"agent_llm\"]}) # THIS IS MODIFIED\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True).with_config({\"run_name\":\"Agent\"}) #THIS IS MODIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StreamlitCallbackHandler.on_tool_start callback: StreamlitAPIException()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `where_cat_is_hiding` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StreamlitCallbackHandler.on_tool_end callback: StreamlitAPIException()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mon the shelf\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StreamlitCallbackHandler.on_tool_start callback: StreamlitAPIException()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_items` with `{'place': 'on the shelf'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StreamlitCallbackHandler.on_tool_end callback: StreamlitAPIException()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mbooks, penciles and pictures\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StreamlitCallbackHandler.on_agent_finish callback: StreamlitAPIException()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mFinal Answer: The items located where the cat is hiding, on the shelf, are books, pencils, and pictures.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.callbacks.streamlit import StreamlitCallbackHandler\n",
    "\n",
    "st_callback = StreamlitCallbackHandler(st.container())\n",
    "\n",
    "agent_executor_openai_prompt_output = agent_executor.invoke({\n",
    "    \"input\": \"what's items are located where the cat is hiding?\",\n",
    "    \"chat_history\": chat_history,\n",
    "    \"tools\":tools\n",
    "    },\n",
    "    {\n",
    "    \"callbacks\": [st_callback]\n",
    "    }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing React Agent Prompt\n",
    "\n",
    "Notice that it has *no chat_history*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{tools}\u001b[0m\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [\u001b[33;1m\u001b[1;3m{tool_names}\u001b[0m]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "Thought:\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "react_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_agent = create_react_agent(llm, tools, react_prompt)\n",
    "# react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the *OpenAI Tools Agent* prompt, the react agent prompt has *no* `ChatpromptTemplate` and the output is `ReActSingleInputOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mFirst, I need to find out where the cat is hiding.\n",
      "Action: where_cat_is_hiding\n",
      "Action Input: None\u001b[0m"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:1182\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:1204\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m-> 1204\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/tools.py:419\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/tools.py:373\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m     parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/tools.py:275\u001b[0m, in \u001b[0;36mBaseTool._parse_input\u001b[0;34m(self, tool_input)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     key_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__fields__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     input_args\u001b[38;5;241m.\u001b[39mvalidate({key_: tool_input})\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m react_agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39mreact_agent, tools\u001b[38;5;241m=\u001b[39mtools, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#.with_config({\"run_name\":\"Agent\"}) \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m agent_executor_react_prompt_output \u001b[38;5;241m=\u001b[39m \u001b[43mreact_agent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms items are located where the cat is hiding?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# \"chat_history\": chat_history\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:1391\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1391\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1400\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1401\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:1097\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1090\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1095\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1097\u001b[0m         [\n\u001b[1;32m   1098\u001b[0m             a\n\u001b[1;32m   1099\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1100\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1101\u001b[0m                 color_mapping,\n\u001b[1;32m   1102\u001b[0m                 inputs,\n\u001b[1;32m   1103\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1104\u001b[0m                 run_manager,\n\u001b[1;32m   1105\u001b[0m             )\n\u001b[1;32m   1106\u001b[0m         ]\n\u001b[1;32m   1107\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:1097\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1090\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1095\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1097\u001b[0m         [\n\u001b[1;32m   1098\u001b[0m             a\n\u001b[1;32m   1099\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1100\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1101\u001b[0m                 color_mapping,\n\u001b[1;32m   1102\u001b[0m                 inputs,\n\u001b[1;32m   1103\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1104\u001b[0m                 run_manager,\n\u001b[1;32m   1105\u001b[0m             )\n\u001b[1;32m   1106\u001b[0m         ]\n\u001b[1;32m   1107\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "react_agent_executor = AgentExecutor(agent=react_agent, tools=tools, verbose=True) #.with_config({\"run_name\":\"Agent\"}) \n",
    "\n",
    "agent_executor_react_prompt_output = react_agent_executor.invoke({\n",
    "    \"input\": \"what's items are located where the cat is hiding?\",\n",
    "    # \"chat_history\": chat_history\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**React prompt agent won't work with Chat models, only OpenAI non-chat model**. Let's see if this changes in the React Chat Agent prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing React Chat Agent Prompt\n",
    "\n",
    "Notice that this one has *chat_history*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{tools}\u001b[0m\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [\u001b[33;1m\u001b[1;3m{tool_names}\u001b[0m]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "Final Answer: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "New input: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "react_chat_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m llm_bound_tools \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind_tools(tools)\n\u001b[1;32m      3\u001b[0m chat_history \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m      5\u001b[0m react_chat_agent \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 6\u001b[0m     \u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magent_scratchpad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_to_openai_tool_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintermediate_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Part of the prompt as well\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Part of the prompt as well\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreact_chat_prompt\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m|\u001b[39m llm_bound_tools\u001b[38;5;241m.\u001b[39mwith_config({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m]}) \u001b[38;5;66;03m# THIS IS MODIFIED\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;241m|\u001b[39m OpenAIToolsAgentOutputParser()\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m react_chat_agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39mreact_chat_agent, tools\u001b[38;5;241m=\u001b[39mtools, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mwith_config({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \u001b[38;5;66;03m#THIS IS MODIFIED\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:433\u001b[0m, in \u001b[0;36mRunnable.__ror__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ror__\u001b[39m(\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    425\u001b[0m     other: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    430\u001b[0m     ],\n\u001b[1;32m    431\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunnableSerializable[Other, Output]:\n\u001b[1;32m    432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compose this runnable with another object to create a RunnableSequence.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableSequence(\u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:4367\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   4365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableLambda(cast(Callable[[Input], Output], thing))\n\u001b[1;32m   4366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(thing, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m-> 4367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Runnable[Input, Output], \u001b[43mRunnableParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthing\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   4368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4370\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a Runnable, callable or dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4372\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:2559\u001b[0m, in \u001b[0;36mRunnableParallel.__init__\u001b[0;34m(self, _RunnableParallel__steps, **kwargs)\u001b[0m\n\u001b[1;32m   2556\u001b[0m merged \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__steps} \u001b[38;5;28;01mif\u001b[39;00m __steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2557\u001b[0m merged\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m-> 2559\u001b[0m     steps\u001b[38;5;241m=\u001b[39m{key: coerce_to_runnable(r) \u001b[38;5;28;01mfor\u001b[39;00m key, r \u001b[38;5;129;01min\u001b[39;00m merged\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   2560\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:2559\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2556\u001b[0m merged \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__steps} \u001b[38;5;28;01mif\u001b[39;00m __steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2557\u001b[0m merged\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m-> 2559\u001b[0m     steps\u001b[38;5;241m=\u001b[39m{key: \u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, r \u001b[38;5;129;01min\u001b[39;00m merged\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   2560\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:4369\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   4367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Runnable[Input, Output], RunnableParallel(thing))\n\u001b[1;32m   4368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4370\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a Runnable, callable or dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4372\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'list'>"
     ]
    }
   ],
   "source": [
    "tools = [where_cat_is_hiding, get_items]\n",
    "llm_bound_tools = llm.bind_tools(tools)\n",
    "chat_history = [] \n",
    "\n",
    "react_chat_agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(x[\"intermediate_steps\"]), # Part of the prompt as well\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"], # Part of the prompt as well\n",
    "        \"tools\": tools,\n",
    "        \"tool_names\": \"\\n\".join([i.get_name() for i in tools])\n",
    "    }\n",
    "    | react_chat_prompt\n",
    "    | llm_bound_tools.with_config({\"tags\": [\"agent_llm\"]}) # THIS IS MODIFIED\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "react_chat_agent_executor = AgentExecutor(agent=react_chat_agent, tools=tools, verbose=True).with_config({\"run_name\":\"Agent\"}) #THIS IS MODIFIED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The react chat agent has chat messaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# react_chat_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Input to PromptTemplate is missing variables {'tools', 'tool_names'}.  Expected: ['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'] Received: ['agent_scratchpad', 'input', 'chat_history']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent_executor_react_chat_prompt_output \u001b[38;5;241m=\u001b[39m \u001b[43mreact_chat_agent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms items are located where the cat is hiding?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:4063\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4057\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4058\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4059\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4060\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4061\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4062\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4064\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4065\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4066\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4067\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:1391\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1391\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1400\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1401\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:1097\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1090\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1095\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1097\u001b[0m         [\n\u001b[1;32m   1098\u001b[0m             a\n\u001b[1;32m   1099\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1100\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1101\u001b[0m                 color_mapping,\n\u001b[1;32m   1102\u001b[0m                 inputs,\n\u001b[1;32m   1103\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1104\u001b[0m                 run_manager,\n\u001b[1;32m   1105\u001b[0m             )\n\u001b[1;32m   1106\u001b[0m         ]\n\u001b[1;32m   1107\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:1097\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1090\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1095\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1097\u001b[0m         [\n\u001b[1;32m   1098\u001b[0m             a\n\u001b[1;32m   1099\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1100\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1101\u001b[0m                 color_mapping,\n\u001b[1;32m   1102\u001b[0m                 inputs,\n\u001b[1;32m   1103\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1104\u001b[0m                 run_manager,\n\u001b[1;32m   1105\u001b[0m             )\n\u001b[1;32m   1106\u001b[0m         ]\n\u001b[1;32m   1107\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:1125\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1125\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain/agents/agent.py:486\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a streaming\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# fashion to make it possible to get access to the individual LLM tokens\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# when using stream_log with the Agent Executor.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m         final_output \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:2427\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   2422\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2423\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   2424\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2427\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:2414\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   2409\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2410\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2411\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2412\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2413\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2414\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2415\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2416\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   2417\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2418\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2419\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:1494\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1494\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:2378\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2370\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   2371\u001b[0m         final_pipeline,\n\u001b[1;32m   2372\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2375\u001b[0m         ),\n\u001b[1;32m   2376\u001b[0m     )\n\u001b[0;32m-> 2378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2379\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:1032\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m final: Input\n\u001b[1;32m   1030\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1034\u001b[0m         final \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:4167\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   4162\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4163\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   4164\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 4167\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   4168\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   4169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4170\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   4171\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:1032\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m final: Input\n\u001b[1;32m   1030\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1034\u001b[0m         final \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:1042\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         final \u001b[38;5;241m=\u001b[39m final \u001b[38;5;241m+\u001b[39m chunk  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1042\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:577\u001b[0m, in \u001b[0;36mRunnable.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m    570\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m    572\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m    573\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m    Default implementation of stream, which calls invoke.\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03m    Subclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/prompts/base.py:113\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    112\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags)\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/base.py:1243\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1239\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1240\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1241\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1242\u001b[0m         Output,\n\u001b[0;32m-> 1243\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1246\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1247\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1251\u001b[0m     )\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1253\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/open_ai/lib/python3.9/site-packages/langchain_core/prompts/base.py:98\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m     96\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(inner_input)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is missing variables \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(inner_input\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_input)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Input to PromptTemplate is missing variables {'tools', 'tool_names'}.  Expected: ['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'] Received: ['agent_scratchpad', 'input', 'chat_history']\""
     ]
    }
   ],
   "source": [
    "agent_executor_react_chat_prompt_output = react_chat_agent_executor.invoke({\n",
    "    \"input\": \"what's items are located where the cat is hiding?\",\n",
    "    \"chat_history\": chat_history,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"what's items are located where the cat is hiding?\",\n",
       " 'chat_history': [],\n",
       " 'output': 'The items located where the cat is hiding, under the bed, are socks, shoes, and dust bunnies.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor_react_chat_prompt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
