{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph with Multi-Agent Workflow\n",
    "\n",
    "Multiple agents interacting in Workflow design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    ChatMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    ")\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import FunctionMessage\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key solely to use embedding model\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools to be called by LLM\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "tool_executor = ToolExecutor(tools) # Can invoke an action???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tools to llm\n",
    "llm_bound = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_f12XooXziw7ecQ2iY75U7CJF', 'function': {'arguments': '{\"query\":\"Universitario match result last night\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 90, 'total_tokens': 114}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f798cd8a-e3c6-4778-89e6-a5de3717c924-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Universitario match result last night'}, 'id': 'call_f12XooXziw7ecQ2iY75U7CJF'}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_call = llm_bound.invoke(\"who played against Universitario last night?\")\n",
    "sample_call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool_calls': [{'id': 'call_f12XooXziw7ecQ2iY75U7CJF', 'function': {'arguments': '{\"query\":\"Universitario match result last night\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}\n",
      "dict_keys(['tool_calls'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'Universitario match result last night'},\n",
       "  'id': 'call_f12XooXziw7ecQ2iY75U7CJF'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sample_call.additional_kwargs)\n",
    "print(sample_call.additional_kwargs.keys())\n",
    "sample_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tool_calls'])\n",
      "[{'id': 'call_f12XooXziw7ecQ2iY75U7CJF', 'function': {'arguments': '{\"query\":\"Universitario match result last night\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Universitario match result last night'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"])\n",
    "\n",
    "print(sample_call.additional_kwargs.keys())\n",
    "print(sample_call.additional_kwargs[\"tool_calls\"])\n",
    "\n",
    "# json.loads(sample_call.tool_calls[0][\"args\"]) # ERROR, single quote string like dict cannot be converted to dict\n",
    "\n",
    "json.loads(sample_call.additional_kwargs[\"tool_calls\"][0][\"function\"][\"arguments\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool invocation is the recipe needed to be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolInvocation(tool='tavily_search_results_json', tool_input={'query': 'Universitario match result last night'})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invocation_sample = ToolInvocation(\n",
    "        tool=sample_call.additional_kwargs[\"tool_calls\"][0][\"function\"][\"name\"],\n",
    "        tool_input=json.loads(sample_call.additional_kwargs[\"tool_calls\"][0][\"function\"][\"arguments\"]),\n",
    "    )\n",
    "\n",
    "invocation_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The executor (made up of the tools themselves) will execute the recipe (invocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.sofascore.com/team/football/universitario/2305',\n",
       "  'content': 'Universitario previous match was against Comerciantes Unidos in Liga 1, the match ended with result 6 - 0 (Universitario won the match). Universitario fixtures tab is showing the last 100 football matches with statistics and win/draw/lose icons. There are also all Universitario scheduled matches that they are going to play in the future.'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_executor.invoke(invocation_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent state to build graph\n",
    "class AgentState(TypedDict):\n",
    "    # The `add_messages` function within the annotation defines\n",
    "    # *how* updates should be merged into the state.\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Node to call model (tool calling, ie. output provides expected structured entry)\n",
    "def call_model(state):\n",
    "    messages = state['messages']\n",
    "    response = llm_bound.invoke(messages)\n",
    "    \n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Node to actually execute tool\n",
    "def call_tool(state):\n",
    "    messages = state['messages']\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    action = ToolInvocation(\n",
    "        \n",
    "        # Get the name of the tool to use\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "\n",
    "        \n",
    "        tool_input=json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"]),\n",
    "    )\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
